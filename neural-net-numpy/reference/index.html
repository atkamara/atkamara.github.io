<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Reference - Neural-Network-Numpy(NNN)</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Reference";
        var mkdocs_page_input_path = "reference.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Neural-Network-Numpy(NNN)
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Neural-Net-Numpy(NNN)</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../tutorials/">Tutorials</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../how-to-guides/">How-To Guides</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Reference</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#table-of-contents">Table of Contents</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#section-1-layers">Section 1. layers</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.layers">layers</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.layers.Activation">Activation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.layers.Fullyconnected">Fullyconnected</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#section-2-activation-functions">Section 2. activation functions</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.activation">activation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.activation.ELU">ELU</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.ELU.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.ELU.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.activation.LeakyReLU">LeakyReLU</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.LeakyReLU.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.LeakyReLU.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.activation.ReLU">ReLU</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.ReLU.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.ReLU.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.activation.Softmax">Softmax</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.Softmax.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.Softmax.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.activation.Tanh">Tanh</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.Tanh.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.Tanh.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.activation.Σ">Σ</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.Σ.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.Σ.grad">grad</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.Σ.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.activation.σ">σ</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.σ.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.activation.σ.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#section-3-neural-network-architectures">Section 3. neural network architectures</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.architecture">architecture</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.architecture.Sequential">Sequential</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.architecture.Sequential.__init__">__init__</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.architecture.Sequential.train">train</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#section-4-initialisation-functions">Section 4. initialisation functions</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.init_funcs">init_funcs</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.init_funcs.XavierHe">XavierHe</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.init_funcs.XHReluuniform">XHReluuniform</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.init_funcs.XHsigmoiduniform">XHsigmoiduniform</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.init_funcs.zeros">zeros</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#section-5-cost-functions">Section 5. cost functions</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.cost">cost</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.cost.BinaryCrossEntropy">BinaryCrossEntropy</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.cost.BinaryCrossEntropy.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.cost.BinaryCrossEntropy.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.cost.CrossEntropy">CrossEntropy</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.cost.CrossEntropy.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.cost.CrossEntropy.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.cost.MSE">MSE</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.cost.MSE.compute">compute</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.cost.MSE.pr">pr</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#section-6-metrics">Section 6. metrics</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.metrics">metrics</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.metrics.MAE">MAE</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.metrics.MAE.compute">compute</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.metrics.accuracy">accuracy</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.metrics.accuracy.__init__">__init__</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.metrics.accuracy.compute">compute</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#section-7-database-management">Section 7. database management</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.db">db</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.db.DBmanager">DBmanager</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.db.DBmanager.__start">__start</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.db.DBmanager.add_table">add_table</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.db.get_instance">get_instance</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.db.update_instance">update_instance</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#section-8-data-preparation-functions">Section 8. data preparation functions</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.pipeline">pipeline</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.pipeline.Batch">Batch</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.pipeline.Batch.__init__">__init__</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.pipeline.get_ix">get_ix</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.pipeline.onehot">onehot</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.pipeline.scaler">scaler</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.pipeline.shuffle">shuffle</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#9-class-models-used-to-build-other-classes">9. Class Models used to build other classes</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.model">model</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.model.Architecture">Architecture</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.model.Cost">Cost</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Cost.clip">clip</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#neural_net.model.Cost.clip--parameters">Parameters</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#neural_net.model.Cost.clip--returns">Returns</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#neural_net.model.Cost.clip--see-also">See Also</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#neural_net.model.Cost.clip--notes">Notes</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#neural_net.model.Cost.clip--examples">Examples</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.model.Define">Define</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Define.__add__">__add__</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Define.__repr__">__repr__</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Define.compute_store">compute_store</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Define.predict">predict</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Define.update">update</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Define.updateW">updateW</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.model.Layer">Layer</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.model.Metrics">Metrics</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.model.Neurons">Neurons</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Neurons.__sub__">__sub__</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Neurons.grad">grad</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Neurons.instantiateW">instantiateW</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Neurons.n">n</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.model.Neurons.storeW">storeW</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#10-utility-functions">10. Utility functions</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.utils">utils</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.utils.HouseDatasetDownloader">HouseDatasetDownloader</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.utils.HouseDatasetDownloader.load_dataset">load_dataset</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.utils.IrisDatasetDownloader">IrisDatasetDownloader</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.utils.IrisDatasetDownloader.load_dataset">load_dataset</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.utils.Pearson">Pearson</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#neural_net.utils.Pearson.__init__">__init__</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.utils.get_module_path">get_module_path</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.utils.make_circle_data">make_circle_data</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.utils.now">now</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#neural_net.utils.unfold">unfold</a>
    </li>
    </ul>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Neural-Network-Numpy(NNN)</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Reference</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="reference-page">Reference Page</h1>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li>layers</li>
<li>activation functions</li>
<li>neural network architectures</li>
<li>initialisation functions</li>
<li>cost functions</li>
<li>metrics</li>
<li>database management</li>
<li>data preparation functions</li>
<li>Class Models used to build other classes</li>
<li>Utility functions</li>
</ol>
<h2 id="introduction">Introduction</h2>
<p>This reference page provides an overview of all functions, classes and methods available in the neural_net project</p>
<h2 id="section-1-layers">Section 1. layers</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.layers"></a>
  <div class="doc doc-contents first">
  
      <p>This module provides Layer classes</p>
<ul>
<li><code>Fullyconnected</code> </li>
<li><code>Activation</code></li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.layers.Activation" class="doc doc-heading">
          <code>Activation</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Layer" href="#neural_net.model.Layer">Layer</a></code></p>

  
      <p>Activation Layer.</p>
<p>This layer handles activation for a given activation function</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>func</code></b>
                  (<code>callable</code>)
              –
              <div class="doc-md-description">
                <p>an activation function like :func:<code>~activation.σ</code></p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
            <details class="quote">
              <summary>Source code in <code>neural_net\layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Activation</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Activation Layer.</span>

<span class="sd">    This layer handles activation for a given activation function</span>

<span class="sd">    Args:</span>
<span class="sd">        func (callable): an activation function like :func:`~activation.σ`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">func</span><span class="p">,</span><span class="o">*</span><span class="n">kargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.layers.Fullyconnected" class="doc doc-heading">
          <code>Fullyconnected</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Layer" href="#neural_net.model.Layer">Layer</a></code></p>

  
      <p>A fully connected neural network layer.</p>
<p>This layer takes an input vector and transforms it linearly using a weights matrix.
The product is then subjected to a non-linear activation function.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>n_in</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Number of input features.</p>
              </div>
            </li>
            <li>
              <b><code>n_out</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Number of output features .</p>
              </div>
            </li>
            <li>
              <b><code>init_method</code></b>
                  (<code>callable</code>)
              –
              <div class="doc-md-description">
                <p>function that initializes weights and takes in as parameters func(n_in,n_out) -&gt; array.shape = (n_in +1, n_out)</p>
              </div>
            </li>
            <li>
              <b><code>func</code></b>
                  (<code>callable</code>, default:
                      <code><a class="autorefs autorefs-internal" title="neural_net.activation.Σ" href="#neural_net.activation.Σ">Σ</a></code>
)
              –
              <div class="doc-md-description">
                <p>default is :func:<code>~activation.Σ</code></p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
            <details class="quote">
              <summary>Source code in <code>neural_net\layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Fullyconnected</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A fully connected neural network layer.</span>

<span class="sd">    This layer takes an input vector and transforms it linearly using a weights matrix.</span>
<span class="sd">    The product is then subjected to a non-linear activation function.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_in (int): Number of input features.</span>
<span class="sd">        n_out (int): Number of output features .</span>
<span class="sd">        init_method (callable): function that initializes weights and takes in as parameters func(n_in,n_out) -&gt; array.shape = (n_in +1, n_out)</span>
<span class="sd">        func (callable): default is :func:`~activation.Σ`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_in</span> <span class="p">:</span><span class="nb">int</span><span class="p">,</span><span class="n">n_out</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span><span class="n">init_method</span><span class="p">:</span><span class="nb">callable</span><span class="p">,</span><span class="n">func</span><span class="p">:</span><span class="nb">callable</span><span class="o">=</span><span class="n">Σ</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>


</div>




  </div>

  </div>

</div><h2 id="section-2-activation-functions">Section 2. activation functions</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.activation"></a>
  <div class="doc doc-contents first">
  
      <p>This module provides classes for several types of activation functions</p>
<ul>
<li><code>Σ</code> - Linear combination of weights and biases</li>
<li><code>σ</code> - sigmoid activation</li>
<li><code>Softmax</code>- Softmax activation</li>
<li><code>LeakyReLU</code>- Leaky rectified linear unit activation</li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.activation.ELU" class="doc doc-heading">
          <code>ELU</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Neurons" href="#neural_net.model.Neurons">Neurons</a></code></p>

  
      <p>A class representing the Exponential Linear Unit (ELU) activation function.</p>
<p>
<script type="math/tex; mode=display">
\mathrm{\mathit{H}}(z) = \begin{cases}
    z & \text{if } z \geq 0  \\ % & is your "\tab"
    \alpha (e^{z} - 1) & \text{if } z < 0
\end{cases}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>preds</code></b>
              –
              <div class="doc-md-description">
                <p>predicted values.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.ELU.compute" href="#neural_net.activation.ELU.compute">compute</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the ELU activation for input matrix X.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.ELU.pr" href="#neural_net.activation.ELU.pr">pr</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the derivative of the ELU function.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>α</code></b>
                  (<code>float</code>, default:
                      <code>0.001</code>
)
              –
              <div class="doc-md-description">
                <p>The slope coefficient for negative values (default is 0.001).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
            <details class="quote">
              <summary>Source code in <code>neural_net\activation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ELU</span><span class="p">(</span><span class="n">Neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class representing the Exponential Linear Unit (ELU) activation function.</span>

<span class="sd">    $$</span>
<span class="sd">    \mathrm{\mathit{H}}(z) = \begin{cases}</span>
<span class="sd">        z &amp; \text{if } z \geq 0  \\ % &amp; is your &quot;\tab&quot;</span>
<span class="sd">        \alpha (e^{z} - 1) &amp; \text{if } z &lt; 0</span>
<span class="sd">    \end{cases}</span>
<span class="sd">    $$</span>

<span class="sd">    Attributes:</span>
<span class="sd">        preds: predicted values.</span>

<span class="sd">    Methods:</span>
<span class="sd">        compute(X):</span>
<span class="sd">            Computes the ELU activation for input matrix X.</span>

<span class="sd">        pr():</span>
<span class="sd">            Computes the derivative of the ELU function.</span>

<span class="sd">    Args:</span>
<span class="sd">        α (float): The slope coefficient for negative values (default is 0.001).</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Layer</span><span class="p">:</span><span class="n">Layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">α</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span> 
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative of the ELU function.</span>

<span class="sd">        $$</span>
<span class="sd">        \mathrm{\mathit{H}}&#39;(z) = \begin{cases}</span>
<span class="sd">            1 &amp; \text{if } z \geq 0  \\ % &amp; </span>
<span class="sd">            \mathrm{\mathit{H}}(z) + \alpha &amp; \text{if } z &lt; 0</span>
<span class="sd">        \end{cases}</span>
<span class="sd">        $$</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">neg</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">+</span> <span class="n">neg</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="o">~</span><span class="n">neg</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the ELU activation for input matrix X.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: ELU activation result of shape (n, n_out).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">neg</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="o">~</span><span class="n">neg</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.ELU.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the ELU activation for input matrix X.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Input matrix of shape (n, k).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: ELU activation result of shape (n, n_out).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the ELU activation for input matrix X.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: ELU activation result of shape (n, n_out).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">neg</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="o">~</span><span class="n">neg</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.ELU.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative of the ELU function.</p>
<p>
<script type="math/tex; mode=display">
\mathrm{\mathit{H}}'(z) = \begin{cases}
    1 & \text{if } z \geq 0  \\ % & 
    \mathrm{\mathit{H}}(z) + \alpha & \text{if } z < 0
\end{cases}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative matrix.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span> 
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative of the ELU function.</span>

<span class="sd">    $$</span>
<span class="sd">    \mathrm{\mathit{H}}&#39;(z) = \begin{cases}</span>
<span class="sd">        1 &amp; \text{if } z \geq 0  \\ % &amp; </span>
<span class="sd">        \mathrm{\mathit{H}}(z) + \alpha &amp; \text{if } z &lt; 0</span>
<span class="sd">    \end{cases}</span>
<span class="sd">    $$</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">neg</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">+</span> <span class="n">neg</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="o">~</span><span class="n">neg</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.activation.LeakyReLU" class="doc doc-heading">
          <code>LeakyReLU</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Neurons" href="#neural_net.model.Neurons">Neurons</a></code></p>

  
      <p>A class representing the Leaky Rectified Linear Unit (LeakyReLU) activation function.</p>
<p>
<script type="math/tex; mode=display">
\mathrm{\mathit{H}}(z) = \begin{cases}
    z & \text{if }  z \geq 0  \\ % & is your "\tab"
    \alpha z & \text{if } z < 0
\end{cases}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>preds</code></b>
              –
              <div class="doc-md-description">
                <p>predicted values.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.LeakyReLU.compute" href="#neural_net.activation.LeakyReLU.compute">compute</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the LeakyReLU activation for input matrix X.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.LeakyReLU.pr" href="#neural_net.activation.LeakyReLU.pr">pr</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the derivative of the LeakyReLU function.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>α</code></b>
                  (<code>float</code>, default:
                      <code>0.001</code>
)
              –
              <div class="doc-md-description">
                <p>The slope coefficient for negative values (default is 0.001).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
            <details class="quote">
              <summary>Source code in <code>neural_net\activation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LeakyReLU</span><span class="p">(</span><span class="n">Neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class representing the Leaky Rectified Linear Unit (LeakyReLU) activation function.</span>

<span class="sd">    $$</span>
<span class="sd">    \mathrm{\mathit{H}}(z) = \begin{cases}</span>
<span class="sd">        z &amp; \text{if }  z \geq 0  \\ % &amp; is your &quot;\tab&quot;</span>
<span class="sd">        \alpha z &amp; \text{if } z &lt; 0</span>
<span class="sd">    \end{cases}</span>
<span class="sd">    $$</span>

<span class="sd">    Attributes:</span>
<span class="sd">        preds: predicted values.</span>

<span class="sd">    Methods:</span>
<span class="sd">        compute(X):</span>
<span class="sd">            Computes the LeakyReLU activation for input matrix X.</span>

<span class="sd">        pr():</span>
<span class="sd">            Computes the derivative of the LeakyReLU function.</span>

<span class="sd">    Args:</span>
<span class="sd">        α (float): The slope coefficient for negative values (default is 0.001).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Layer</span><span class="p">:</span><span class="n">Layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">α</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">.001</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span> 
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative of the LeakyReLU function.</span>
<span class="sd">        $$</span>
<span class="sd">        \mathrm{\mathit{H}}&#39;(z) = \begin{cases}</span>
<span class="sd">        1 &amp; \text{if } z \geq 0  \\ % &amp;</span>
<span class="sd">        \alpha &amp; \text{if } z &lt; 0</span>
<span class="sd">        \end{cases}</span>
<span class="sd">        $$</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">neg</span><span class="o">:=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="o">~</span><span class="n">neg</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the LeakyReLU activation for input matrix X.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: LeakyReLU activation result of shape (n, n_out).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">neg</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">+</span> <span class="o">~</span><span class="n">neg</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.LeakyReLU.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the LeakyReLU activation for input matrix X.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Input matrix of shape (n, k).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: LeakyReLU activation result of shape (n, n_out).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the LeakyReLU activation for input matrix X.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: LeakyReLU activation result of shape (n, n_out).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">neg</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">+</span> <span class="o">~</span><span class="n">neg</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.LeakyReLU.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative of the LeakyReLU function.
<script type="math/tex; mode=display">
\mathrm{\mathit{H}}'(z) = \begin{cases}
1 & \text{if } z \geq 0  \\ % &
\alpha & \text{if } z < 0
\end{cases}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative matrix.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span> 
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative of the LeakyReLU function.</span>
<span class="sd">    $$</span>
<span class="sd">    \mathrm{\mathit{H}}&#39;(z) = \begin{cases}</span>
<span class="sd">    1 &amp; \text{if } z \geq 0  \\ % &amp;</span>
<span class="sd">    \alpha &amp; \text{if } z &lt; 0</span>
<span class="sd">    \end{cases}</span>
<span class="sd">    $$</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">neg</span><span class="o">:=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="o">~</span><span class="n">neg</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.activation.ReLU" class="doc doc-heading">
          <code>ReLU</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Neurons" href="#neural_net.model.Neurons">Neurons</a></code></p>

  
      <p>A class representing the Rectified Linear Unit (ReLU) activation function.</p>
<p>
<script type="math/tex; mode=display">
\mathrm{\mathit{H}}(z) = \begin{cases}
    z & \text{if } z \geq 0  \\ % & is your "\tab"
    0 & \text{if } z < 0
\end{cases}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>preds</code></b>
              –
              <div class="doc-md-description">
                <p>predicted values.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.ReLU.compute" href="#neural_net.activation.ReLU.compute">compute</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the ReLU activation for input matrix X.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.ReLU.pr" href="#neural_net.activation.ReLU.pr">pr</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the derivative of the ReLU function.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>neural_net\activation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">Neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class representing the Rectified Linear Unit (ReLU) activation function.</span>

<span class="sd">    $$</span>
<span class="sd">    \mathrm{\mathit{H}}(z) = \begin{cases}</span>
<span class="sd">        z &amp; \text{if } z \geq 0  \\ % &amp; is your &quot;\tab&quot;</span>
<span class="sd">        0 &amp; \text{if } z &lt; 0</span>
<span class="sd">    \end{cases}</span>
<span class="sd">    $$</span>

<span class="sd">    Attributes:</span>
<span class="sd">        preds: predicted values.</span>

<span class="sd">    Methods:</span>
<span class="sd">        compute(X):</span>
<span class="sd">            Computes the ReLU activation for input matrix X.</span>

<span class="sd">        pr():</span>
<span class="sd">            Computes the derivative of the ReLU function.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Layer</span><span class="p">:</span><span class="n">Layer</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span> 
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative of the ReLU function.</span>

<span class="sd">        $$</span>
<span class="sd">        \mathrm{\mathit{H}}(z) = \begin{cases}</span>
<span class="sd">            1 &amp; \text{if } z \geq 0  \\ % &amp; is your &quot;\tab&quot;</span>
<span class="sd">            0 &amp; \text{if } z &lt; 0</span>
<span class="sd">        \end{cases}</span>
<span class="sd">        $$</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">0</span> <span class="c1">#for casting bool to int</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the ReLU activation for input matrix X.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: ReLU activation result of shape (n, n_out).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.ReLU.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the ReLU activation for input matrix X.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Input matrix of shape (n, k).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: ReLU activation result of shape (n, n_out).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the ReLU activation for input matrix X.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: ReLU activation result of shape (n, n_out).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.ReLU.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative of the ReLU function.</p>
<p>
<script type="math/tex; mode=display">
\mathrm{\mathit{H}}(z) = \begin{cases}
    1 & \text{if } z \geq 0  \\ % & is your "\tab"
    0 & \text{if } z < 0
\end{cases}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative matrix.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span> 
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative of the ReLU function.</span>

<span class="sd">    $$</span>
<span class="sd">    \mathrm{\mathit{H}}(z) = \begin{cases}</span>
<span class="sd">        1 &amp; \text{if } z \geq 0  \\ % &amp; is your &quot;\tab&quot;</span>
<span class="sd">        0 &amp; \text{if } z &lt; 0</span>
<span class="sd">    \end{cases}</span>
<span class="sd">    $$</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">0</span> <span class="c1">#for casting bool to int</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.activation.Softmax" class="doc doc-heading">
          <code>Softmax</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Neurons" href="#neural_net.model.Neurons">Neurons</a></code></p>

  
      <p>A class representing the softmax activation function.</p>
<p>
<script type="math/tex; mode=display">
\sigma(\mathbf {z_{i}} )=\frac {e^{z_{i}}}{\sum _{j=1}^{k}e^{z_{j}}}\\ {\text{ for }}j=1,\dotsc ,k{\text{ features }}{\text{ and }} z_{i}=(z_{i,1},...,z_{i,n}) \text{ for n observations}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>preds</code></b>
              –
              <div class="doc-md-description">
                <p>predicted values.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.Softmax.compute" href="#neural_net.activation.Softmax.compute">compute</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the Softmax activation for input matrix X.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.Softmax.pr" href="#neural_net.activation.Softmax.pr">pr</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the derivative of the Softmax function.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>neural_net\activation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Softmax</span><span class="p">(</span><span class="n">Neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class representing the softmax activation function.</span>

<span class="sd">    $$</span>
<span class="sd">    \sigma(\mathbf {z_{i}} )=\frac {e^{z_{i}}}{\sum _{j=1}^{k}e^{z_{j}}}\\ {\text{ for }}j=1,\dotsc ,k{\text{ features }}{\text{ and }} z_{i}=(z_{i,1},...,z_{i,n}) \text{ for n observations}</span>
<span class="sd">    $$</span>

<span class="sd">    Attributes:</span>
<span class="sd">        preds: predicted values.</span>

<span class="sd">    Methods:</span>
<span class="sd">        compute(X):</span>
<span class="sd">            Computes the Softmax activation for input matrix X.</span>

<span class="sd">        pr():</span>
<span class="sd">            Computes the derivative of the Softmax function.</span>

<span class="sd">    &quot;&quot;&quot;</span>   
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Layer</span><span class="p">:</span><span class="n">Layer</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative of the Softmax function.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the softmax activation for input matrix X using vectorization with numpy.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Softmax activation result of shape (n, n_out).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">ex</span><span class="o">:=</span><span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">))</span><span class="o">/</span><span class="n">ex</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.Softmax.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the softmax activation for input matrix X using vectorization with numpy.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Input matrix of shape (n, k).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Softmax activation result of shape (n, n_out).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the softmax activation for input matrix X using vectorization with numpy.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Softmax activation result of shape (n, n_out).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">ex</span><span class="o">:=</span><span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">))</span><span class="o">/</span><span class="n">ex</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.Softmax.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative of the Softmax function.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative matrix.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative of the Softmax function.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.activation.Tanh" class="doc doc-heading">
          <code>Tanh</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Neurons" href="#neural_net.model.Neurons">Neurons</a></code></p>

  
      <p>A class representing the Hyperbolic Tangent activation function.</p>
<p>
<script type="math/tex; mode=display">
\tanh(z)={\frac{{\rm{e}}^{z}-{\rm{e}}^{-z}}{{\rm {e}}^{z}+{\rm {e}}^{-z}}}={\frac{{\rm {e}}^{2z}-1}{{\rm{e}}^{2z}+1}}={\frac{1-{\rm{e}}^{-2z}}{1+{\rm {e}}^{-2z}}}
</script>
</p>
<p>
<script type="math/tex; mode=display">
Tanh=2\sigma(2z) - 1
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>preds</code></b>
              –
              <div class="doc-md-description">
                <p>predicted values.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.Tanh.compute" href="#neural_net.activation.Tanh.compute">compute</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the Tanh activation for input matrix X.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.Tanh.pr" href="#neural_net.activation.Tanh.pr">pr</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the derivative of the Tanh function.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>neural_net\activation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Tanh</span><span class="p">(</span><span class="n">Neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class representing the Hyperbolic Tangent activation function.</span>

<span class="sd">    $$</span>
<span class="sd">    \tanh(z)={\frac{{\rm{e}}^{z}-{\rm{e}}^{-z}}{{\rm {e}}^{z}+{\rm {e}}^{-z}}}={\frac{{\rm {e}}^{2z}-1}{{\rm{e}}^{2z}+1}}={\frac{1-{\rm{e}}^{-2z}}{1+{\rm {e}}^{-2z}}}</span>
<span class="sd">    $$</span>

<span class="sd">    $$</span>
<span class="sd">    Tanh=2\sigma(2z) - 1</span>
<span class="sd">    $$</span>

<span class="sd">    Attributes:</span>
<span class="sd">        preds: predicted values.</span>

<span class="sd">    Methods:</span>
<span class="sd">        compute(X):</span>
<span class="sd">            Computes the Tanh activation for input matrix X.</span>

<span class="sd">        pr():</span>
<span class="sd">            Computes the derivative of the Tanh function.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Layer</span><span class="p">:</span><span class="n">Layer</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative of the Tanh function.</span>

<span class="sd">        $$</span>
<span class="sd">         \tanh &#39;={\frac {1}{\cosh ^{2}}}=1-\tanh ^{2}</span>
<span class="sd">        $$</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="o">**</span><span class="mi">2</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the Tanh activation for input matrix X.</span>

<span class="sd">        $$</span>
<span class="sd">        Tanh(X)=2\sigma(2X) - 1</span>
<span class="sd">        $$</span>

<span class="sd">        where $\sigma$ is defined as follows:</span>

<span class="sd">        $$</span>
<span class="sd">         \sigma (X)={\frac {1}{1+e^{-X}}}</span>
<span class="sd">        $$</span>

<span class="sd">        Args:</span>
<span class="sd">            X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Tanh activation result of shape (n, n_out).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">σ</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">z</span> <span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">σ</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.Tanh.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the Tanh activation for input matrix X.</p>
<p>
<script type="math/tex; mode=display">
Tanh(X)=2\sigma(2X) - 1
</script>
</p>
<p>where $\sigma$ is defined as follows:</p>
<p>
<script type="math/tex; mode=display">
 \sigma (X)={\frac {1}{1+e^{-X}}}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Input matrix of shape (n, k).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Tanh activation result of shape (n, n_out).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the Tanh activation for input matrix X.</span>

<span class="sd">    $$</span>
<span class="sd">    Tanh(X)=2\sigma(2X) - 1</span>
<span class="sd">    $$</span>

<span class="sd">    where $\sigma$ is defined as follows:</span>

<span class="sd">    $$</span>
<span class="sd">     \sigma (X)={\frac {1}{1+e^{-X}}}</span>
<span class="sd">    $$</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Tanh activation result of shape (n, n_out).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">z</span> <span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">σ</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.Tanh.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative of the Tanh function.</p>
<p>
<script type="math/tex; mode=display">
 \tanh '={\frac {1}{\cosh ^{2}}}=1-\tanh ^{2}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative matrix.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative of the Tanh function.</span>

<span class="sd">    $$</span>
<span class="sd">     \tanh &#39;={\frac {1}{\cosh ^{2}}}=1-\tanh ^{2}</span>
<span class="sd">    $$</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="o">**</span><span class="mi">2</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.activation.Σ" class="doc doc-heading">
          <code>Σ</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Neurons" href="#neural_net.model.Neurons">Neurons</a></code></p>

  
      <p>A class representing a linear combination operation.</p>
<p>
<script type="math/tex; mode=display">
\mathrm{\mathit{H}}(z) = z.w + b
</script>
</p>
<p>where w is weights vector and b is bias</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>W</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Weight matrix of shape (k+1, n_out). +1 for bias</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.Σ.compute" href="#neural_net.activation.Σ.compute">compute</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the linear combination of input matrix X and bias vector using weight matrix W.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.Σ.pr" href="#neural_net.activation.Σ.pr">pr</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the derivative of the linear equation with respect to W (matrix X itself).</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.Σ.grad" href="#neural_net.activation.Σ.grad">grad</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Updates weights self.W and computes the new gradient Δ for backpropagation.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><span title="neural_net.activation.Σ.Xb">Xb</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>Concatenates X matrix with a vector of ones</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>neural_net\activation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Σ</span><span class="p">(</span><span class="n">Neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class representing a linear combination operation.</span>

<span class="sd">    $$</span>
<span class="sd">    \mathrm{\mathit{H}}(z) = z.w + b</span>
<span class="sd">    $$</span>

<span class="sd">    where w is weights vector and b is bias</span>

<span class="sd">    Attributes:</span>
<span class="sd">        W (numpy.ndarray): Weight matrix of shape (k+1, n_out). +1 for bias</span>

<span class="sd">    Methods:</span>
<span class="sd">        compute(X):</span>
<span class="sd">            Computes the linear combination of input matrix X and bias vector using weight matrix W.</span>

<span class="sd">        pr():</span>
<span class="sd">            Computes the derivative of the linear equation with respect to W (matrix X itself).</span>

<span class="sd">        grad(Δ):</span>
<span class="sd">            Updates weights self.W and computes the new gradient Δ for backpropagation.</span>
<span class="sd">        Xb():</span>
<span class="sd">            Concatenates X matrix with a vector of ones</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Layer</span><span class="p">:</span><span class="n">Layer</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_method</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;Layer_n_in&#39;</span><span class="p">],</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;Layer_n_out&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Xb</span> <span class="o">=</span> <span class="k">lambda</span> <span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span><span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">(),</span><span class="mi">1</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">instantiateW</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storeW</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative of the linear equation (matrix itself).</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Xb</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the linear combination of input matrix X and bias vector using weight matrix self.W.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Linear combination result of shape (n, n_out).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Xb</span><span class="p">()</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> 

    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Δ</span> <span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Updates weights self.W and computes the gradient for backpropagation.</span>

<span class="sd">        Args:</span>
<span class="sd">            Δ (numpy.ndarray): Gradient from next activation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span>   <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pr</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Δ</span><span class="p">))</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Δ</span> <span class="o">=</span> <span class="n">Δ</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1">#-1 to remove biais</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Δ</span>        
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.Σ.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the linear combination of input matrix X and bias vector using weight matrix self.W.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Input matrix of shape (n, k).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Linear combination result of shape (n, n_out).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the linear combination of input matrix X and bias vector using weight matrix self.W.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Linear combination result of shape (n, n_out).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Xb</span><span class="p">()</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> 
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.Σ.grad" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">grad</span><span class="p">(</span><span class="n">Δ</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Updates weights self.W and computes the gradient for backpropagation.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>Δ</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Gradient from next activation.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Δ</span> <span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates weights self.W and computes the gradient for backpropagation.</span>

<span class="sd">    Args:</span>
<span class="sd">        Δ (numpy.ndarray): Gradient from next activation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span>   <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pr</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Δ</span><span class="p">))</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Δ</span> <span class="o">=</span> <span class="n">Δ</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="c1">#-1 to remove biais</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Δ</span>        
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.Σ.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative of the linear equation (matrix itself).</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative matrix.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative of the linear equation (matrix itself).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Xb</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.activation.σ" class="doc doc-heading">
          <code>σ</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Neurons" href="#neural_net.model.Neurons">Neurons</a></code></p>

  
      <p>A class representing the sigmoid activation function.</p>
<p>
<script type="math/tex; mode=display">
\sigma(z)={\frac{1}{1+e^{-z}}}={\frac{e^{z}}{1+e^{z}}}=1-\sigma(-z)
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>preds</code></b>
              –
              <div class="doc-md-description">
                <p>predicted values.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.σ.compute" href="#neural_net.activation.σ.compute">compute</a></code></td>
            <td>
              <div class="doc-md-description">
                <pre><code>Computes the sigmoid activation for input matrix X.
</code></pre>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.activation.σ.pr" href="#neural_net.activation.σ.pr">pr</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the derivative of the sigmoid function.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>neural_net\activation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">σ</span><span class="p">(</span><span class="n">Neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class representing the sigmoid activation function.</span>

<span class="sd">    $$</span>
<span class="sd">    \sigma(z)={\frac{1}{1+e^{-z}}}={\frac{e^{z}}{1+e^{z}}}=1-\sigma(-z)</span>
<span class="sd">    $$</span>

<span class="sd">    Attributes:</span>
<span class="sd">        preds: predicted values.</span>

<span class="sd">    Methods:</span>
<span class="sd">        compute(X):</span>
<span class="sd">                Computes the sigmoid activation for input matrix X.</span>

<span class="sd">        pr():</span>
<span class="sd">            Computes the derivative of the sigmoid function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Layer</span><span class="p">:</span><span class="n">Layer</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative of the sigmoid function.</span>

<span class="sd">        $$</span>
<span class="sd">        {\begin{aligned}\sigma&#39;(z)&amp;={\frac {e^{z}\cdot (1+e^{z})-e^{z}\cdot e^{z}}{(1+e^{z})^{2}}}\\&amp;={\frac {e^{z}}{(1+e^{z})^{2}}}\\&amp;=\left({\frac {e^{z}}{1+e^{z}}}\right)\left({\frac {1}{1+e^{z}}}\right)\\&amp;=\left({\frac {e^{z}}{1+e^{z}}}\right)\left(1-{\frac {e^{z}}{1+e^{z}}}\right)\\&amp;=\sigma(z)\left(1-\sigma(z)\right)\end{aligned}}</span>
<span class="sd">        $$</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the sigmoid activation for input matrix X  using vectorization with numpy.</span>

<span class="sd">        $$</span>
<span class="sd">         \sigma (X)={\dfrac {1}{1+e^{-X}}}</span>
<span class="sd">        $$</span>

<span class="sd">        Args:</span>
<span class="sd">            X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Sigmoid activation result of shape (n, n_out).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.σ.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the sigmoid activation for input matrix X  using vectorization with numpy.</p>
<p>
<script type="math/tex; mode=display">
 \sigma (X)={\dfrac {1}{1+e^{-X}}}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Input matrix of shape (n, k).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Sigmoid activation result of shape (n, n_out).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the sigmoid activation for input matrix X  using vectorization with numpy.</span>

<span class="sd">    $$</span>
<span class="sd">     \sigma (X)={\dfrac {1}{1+e^{-X}}}</span>
<span class="sd">    $$</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Input matrix of shape (n, k).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Sigmoid activation result of shape (n, n_out).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.activation.σ.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative of the sigmoid function.</p>
<p>
<script type="math/tex; mode=display">
{\begin{aligned}\sigma'(z)&={\frac {e^{z}\cdot (1+e^{z})-e^{z}\cdot e^{z}}{(1+e^{z})^{2}}}\\&={\frac {e^{z}}{(1+e^{z})^{2}}}\\&=\left({\frac {e^{z}}{1+e^{z}}}\right)\left({\frac {1}{1+e^{z}}}\right)\\&=\left({\frac {e^{z}}{1+e^{z}}}\right)\left(1-{\frac {e^{z}}{1+e^{z}}}\right)\\&=\sigma(z)\left(1-\sigma(z)\right)\end{aligned}}
</script>
</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative matrix.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\activation.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative of the sigmoid function.</span>

<span class="sd">    $$</span>
<span class="sd">    {\begin{aligned}\sigma&#39;(z)&amp;={\frac {e^{z}\cdot (1+e^{z})-e^{z}\cdot e^{z}}{(1+e^{z})^{2}}}\\&amp;={\frac {e^{z}}{(1+e^{z})^{2}}}\\&amp;=\left({\frac {e^{z}}{1+e^{z}}}\right)\left({\frac {1}{1+e^{z}}}\right)\\&amp;=\left({\frac {e^{z}}{1+e^{z}}}\right)\left(1-{\frac {e^{z}}{1+e^{z}}}\right)\\&amp;=\sigma(z)\left(1-\sigma(z)\right)\end{aligned}}</span>
<span class="sd">    $$</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">preds</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div><h2 id="section-3-neural-network-architectures">Section 3. neural network architectures</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.architecture"></a>
  <div class="doc doc-contents first">
  
      <p>This module provides neural network architectures
Currently available are</p>
<ul>
<li><code>Sequential</code> - Sequential linear net architecture</li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.architecture.Sequential" class="doc doc-heading">
          <code>Sequential</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Architecture" href="#neural_net.model.Architecture">Architecture</a></code></p>


            <details class="quote">
              <summary>Source code in <code>neural_net\architecture.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Sequential</span><span class="p">(</span><span class="n">Architecture</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">steps</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Layer</span><span class="p">],</span><span class="n">cost</span><span class="p">:</span> <span class="n">Cost</span><span class="p">,</span><span class="n">store</span> <span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a Sequential class.</span>

<span class="sd">        Args:</span>
<span class="sd">            steps (List[Layer]): A list of Layer objects representing the steps.</span>
<span class="sd">            cost (Cost): A Cost object for computing cost information.</span>
<span class="sd">            store (bool): If True disables identification and storage</span>

<span class="sd">        Example:</span>
<span class="sd">        ```python</span>
<span class="sd">                layer1 = Fullyconnected(2,50,init_funcs.zeros)</span>
<span class="sd">                layer2 = Activation(activation.LeakyReLU)</span>
<span class="sd">                my_cost = binaryCrossEntropy</span>
<span class="sd">                my_instance = Sequential(steps=[layer1, layer2], cost=my_cost)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span> <span class="o">=</span> <span class="n">store</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">](</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">y</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">batch</span><span class="p">:</span><span class="n">Batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">α</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span><span class="n">metrics</span> <span class="p">:</span> <span class="n">Metrics</span><span class="o">=</span><span class="n">Empty</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains a neural network model using sequential architecture</span>

<span class="sd">        Args:</span>
<span class="sd">            X (numpy.ndarray): Matrix of training features with shape (n, k), where n is the number of samples</span>
<span class="sd">                              and k is the number of features.</span>
<span class="sd">            y (numpy.ndarray): Target variable with shape (n, 1).</span>
<span class="sd">            batch (Optional[Batch]): Optional Batch object that generates batches from the training data.</span>
<span class="sd">            epochs (int): Maximum number of training epochs.</span>
<span class="sd">            α (float): Learning rate (step size for weight updates).</span>
<span class="sd">            metrics (Metrics): Metrics object that computes evaluation metrics (e.g., accuracy).</span>

<span class="sd">        Example:</span>
<span class="sd">        ```python</span>
<span class="sd">                from neural_net import *</span>
<span class="sd">                # generate your training data</span>
<span class="sd">                &gt;&gt;&gt; n,k = 5000,2</span>
<span class="sd">                &gt;&gt;&gt; X_train = numpy.random.uniform(-100,100,size=(n,k))</span>
<span class="sd">                &gt;&gt;&gt; y_train =( (X_train[:, 0]**2 + X_train[:, 1]**2)/numpy.pi &lt; 1000).reshape(-1,1)+0 </span>
<span class="sd">                &gt;&gt;&gt; NN = architecture.Sequential(</span>
<span class="sd">                         [</span>

<span class="sd">                           layers.Fullyconnected(2,50,init_funcs.XHsigmoiduniform) ,</span>
<span class="sd">                           layers.Activation(activation.σ),</span>
<span class="sd">                           layers.Fullyconnected(50,1,init_funcs.XHsigmoiduniform) ,</span>
<span class="sd">                           layers.Activation(activation.σ),</span>


<span class="sd">                        ],</span>
<span class="sd">                        cost = cost.binaryCrossEntropy</span>
<span class="sd">                    )</span>
<span class="sd">                &gt;&gt;&gt; NN.train(X_train, y_train,metrics=metrics.accuracy))</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Xys</span> <span class="o">=</span> <span class="n">batch</span> <span class="ow">or</span> <span class="p">[(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)]</span>
        <span class="n">epochs</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">ascii</span><span class="o">=</span><span class="s1">&#39; =&#39;</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">epochs</span><span class="p">:</span>

            <span class="k">for</span> <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">Xys</span><span class="p">:</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">α</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">pr</span><span class="p">())</span>

            <span class="n">epochs</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">repr</span><span class="p">,[</span>
                                            <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">],</span>
                                            <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">compute_store</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
                                            <span class="n">m</span><span class="p">,</span>
                                            <span class="n">m</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">)])))</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">updateW</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>      
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.architecture.Sequential.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">store</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initialize a Sequential class.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>steps</code></b>
                  (<code>List[<a class="autorefs autorefs-internal" title="neural_net.model.Layer" href="#neural_net.model.Layer">Layer</a>]</code>)
              –
              <div class="doc-md-description">
                <p>A list of Layer objects representing the steps.</p>
              </div>
            </li>
            <li>
              <b><code>cost</code></b>
                  (<code><a class="autorefs autorefs-internal" title="neural_net.model.Cost" href="#neural_net.model.Cost">Cost</a></code>)
              –
              <div class="doc-md-description">
                <p>A Cost object for computing cost information.</p>
              </div>
            </li>
            <li>
              <b><code>store</code></b>
                  (<code>bool</code>, default:
                      <code>False</code>
)
              –
              <div class="doc-md-description">
                <p>If True disables identification and storage</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>      <p>Example:</p>
<pre><code class="language-python">        layer1 = Fullyconnected(2,50,init_funcs.zeros)
        layer2 = Activation(activation.LeakyReLU)
        my_cost = binaryCrossEntropy
        my_instance = Sequential(steps=[layer1, layer2], cost=my_cost)
</code></pre>

          <details class="quote">
            <summary>Source code in <code>neural_net\architecture.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">steps</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Layer</span><span class="p">],</span><span class="n">cost</span><span class="p">:</span> <span class="n">Cost</span><span class="p">,</span><span class="n">store</span> <span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize a Sequential class.</span>

<span class="sd">    Args:</span>
<span class="sd">        steps (List[Layer]): A list of Layer objects representing the steps.</span>
<span class="sd">        cost (Cost): A Cost object for computing cost information.</span>
<span class="sd">        store (bool): If True disables identification and storage</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">            layer1 = Fullyconnected(2,50,init_funcs.zeros)</span>
<span class="sd">            layer2 = Activation(activation.LeakyReLU)</span>
<span class="sd">            my_cost = binaryCrossEntropy</span>
<span class="sd">            my_instance = Sequential(steps=[layer1, layer2], cost=my_cost)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span> <span class="o">=</span> <span class="n">store</span>
    <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">](</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.architecture.Sequential.train" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">α</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">Empty</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Trains a neural network model using sequential architecture</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>Matrix of training features with shape (n, k), where n is the number of samples
              and k is the number of features.</p>
              </div>
            </li>
            <li>
              <b><code>y</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>Target variable with shape (n, 1).</p>
              </div>
            </li>
            <li>
              <b><code>batch</code></b>
                  (<code>Optional[<a class="autorefs autorefs-internal" title="neural_net.pipeline.Batch" href="#neural_net.pipeline.Batch">Batch</a>]</code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>Optional Batch object that generates batches from the training data.</p>
              </div>
            </li>
            <li>
              <b><code>epochs</code></b>
                  (<code>int</code>, default:
                      <code>100</code>
)
              –
              <div class="doc-md-description">
                <p>Maximum number of training epochs.</p>
              </div>
            </li>
            <li>
              <b><code>α</code></b>
                  (<code>float</code>, default:
                      <code>0.001</code>
)
              –
              <div class="doc-md-description">
                <p>Learning rate (step size for weight updates).</p>
              </div>
            </li>
            <li>
              <b><code>metrics</code></b>
                  (<code><a class="autorefs autorefs-internal" title="neural_net.model.Metrics" href="#neural_net.model.Metrics">Metrics</a></code>, default:
                      <code><span title="neural_net.metrics.Empty">Empty</span></code>
)
              –
              <div class="doc-md-description">
                <p>Metrics object that computes evaluation metrics (e.g., accuracy).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>      <p>Example:</p>
<pre><code class="language-python">        from neural_net import *
        # generate your training data
        &gt;&gt;&gt; n,k = 5000,2
        &gt;&gt;&gt; X_train = numpy.random.uniform(-100,100,size=(n,k))
        &gt;&gt;&gt; y_train =( (X_train[:, 0]**2 + X_train[:, 1]**2)/numpy.pi &lt; 1000).reshape(-1,1)+0 
        &gt;&gt;&gt; NN = architecture.Sequential(
                 [

                   layers.Fullyconnected(2,50,init_funcs.XHsigmoiduniform) ,
                   layers.Activation(activation.σ),
                   layers.Fullyconnected(50,1,init_funcs.XHsigmoiduniform) ,
                   layers.Activation(activation.σ),


                ],
                cost = cost.binaryCrossEntropy
            )
        &gt;&gt;&gt; NN.train(X_train, y_train,metrics=metrics.accuracy))
</code></pre>

          <details class="quote">
            <summary>Source code in <code>neural_net\architecture.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">y</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">batch</span><span class="p">:</span><span class="n">Batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">α</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span><span class="n">metrics</span> <span class="p">:</span> <span class="n">Metrics</span><span class="o">=</span><span class="n">Empty</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains a neural network model using sequential architecture</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Matrix of training features with shape (n, k), where n is the number of samples</span>
<span class="sd">                          and k is the number of features.</span>
<span class="sd">        y (numpy.ndarray): Target variable with shape (n, 1).</span>
<span class="sd">        batch (Optional[Batch]): Optional Batch object that generates batches from the training data.</span>
<span class="sd">        epochs (int): Maximum number of training epochs.</span>
<span class="sd">        α (float): Learning rate (step size for weight updates).</span>
<span class="sd">        metrics (Metrics): Metrics object that computes evaluation metrics (e.g., accuracy).</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">            from neural_net import *</span>
<span class="sd">            # generate your training data</span>
<span class="sd">            &gt;&gt;&gt; n,k = 5000,2</span>
<span class="sd">            &gt;&gt;&gt; X_train = numpy.random.uniform(-100,100,size=(n,k))</span>
<span class="sd">            &gt;&gt;&gt; y_train =( (X_train[:, 0]**2 + X_train[:, 1]**2)/numpy.pi &lt; 1000).reshape(-1,1)+0 </span>
<span class="sd">            &gt;&gt;&gt; NN = architecture.Sequential(</span>
<span class="sd">                     [</span>

<span class="sd">                       layers.Fullyconnected(2,50,init_funcs.XHsigmoiduniform) ,</span>
<span class="sd">                       layers.Activation(activation.σ),</span>
<span class="sd">                       layers.Fullyconnected(50,1,init_funcs.XHsigmoiduniform) ,</span>
<span class="sd">                       layers.Activation(activation.σ),</span>


<span class="sd">                    ],</span>
<span class="sd">                    cost = cost.binaryCrossEntropy</span>
<span class="sd">                )</span>
<span class="sd">            &gt;&gt;&gt; NN.train(X_train, y_train,metrics=metrics.accuracy))</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Xys</span> <span class="o">=</span> <span class="n">batch</span> <span class="ow">or</span> <span class="p">[(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)]</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">ascii</span><span class="o">=</span><span class="s1">&#39; =&#39;</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">epochs</span><span class="p">:</span>

        <span class="k">for</span> <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">Xys</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">α</span><span class="o">*</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">pr</span><span class="p">())</span>

        <span class="n">epochs</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">repr</span><span class="p">,[</span>
                                        <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">],</span>
                                        <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;cost&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">compute_store</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
                                        <span class="n">m</span><span class="p">,</span>
                                        <span class="n">m</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">)])))</span> 
    <span class="bp">self</span><span class="o">.</span><span class="n">updateW</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>      
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div><h2 id="section-4-initialisation-functions">Section 4. initialisation functions</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.init_funcs"></a>
  <div class="doc doc-contents first">
  
      <p>This module provides initialization functions</p>
<ul>
<li><code>zeros(n_in: int, n_out: int)</code> - Initializes a weight matrix with zeros</li>
<li><code>XHsigmoiduniform</code> - AA function representing weight initialization using Xavier (Glorot) initialization for sigmoid activation functions.</li>
<li><code>XHReluuniform</code> - A function representing weight initialization using Xavier (Glorot) initialization for Rectified linear unit(RELU) activation functions.</li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.init_funcs.XavierHe" class="doc doc-heading">
          <code>XavierHe</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>This class implements Xavier Glorot and He initializations.(source Hands on ML)</p>
<p><img alt="png" src="../static/xahe.png" /></p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>random</code></b>
                  (<code>dict</code>)
              –
              <div class="doc-md-description">
                <p>contains generators of random values by distribution. </p>
              </div>
            </li>
            <li>
              <b><code>activation</code></b>
                  (<code>str</code>)
              –
              <div class="doc-md-description">
                <p>Name of activation.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>distribution</code></b>
                  (<code>str[Uniform, Normal]</code>)
              –
              <div class="doc-md-description">
                <p>Name of distribution.</p>
              </div>
            </li>
            <li>
              <b><code>activation</code></b>
                  (<code>str[Sigmoid, Tanh, ReLU]</code>)
              –
              <div class="doc-md-description">
                <p>Name of activation.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>init_func</code></b>
              –
              <div class="doc-md-description">
                <p>func(n_in,n_out,biais=True) for generating random values</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
            <details class="quote">
              <summary>Source code in <code>neural_net\init_funcs.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">XavierHe</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class implements Xavier Glorot and He initializations.(source Hands on ML)</span>

<span class="sd">    ![png](static/xahe.png)</span>

<span class="sd">    Attributes:</span>
<span class="sd">        random (dict): contains generators of random values by distribution. </span>
<span class="sd">        activation (str): Name of activation.</span>

<span class="sd">    Args:</span>
<span class="sd">        distribution (str[&quot;Uniform&quot;,&quot;Normal&quot;]): Name of distribution.</span>
<span class="sd">        activation (str[&quot;Sigmoid&quot;,&quot;Tanh&quot;,&quot;ReLU&quot;]): Name of activation.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        init_func : func(n_in,n_out,biais=True) for generating random values </span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">random</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;Uniform&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">r</span><span class="p">,</span><span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span><span class="p">,</span><span class="n">biais</span> <span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">r</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_in</span><span class="o">+</span><span class="n">biais</span><span class="p">,</span><span class="n">n_out</span><span class="p">)),</span>
        <span class="s2">&quot;Normal&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">σ</span><span class="p">,</span><span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span><span class="p">,</span><span class="n">biais</span> <span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">σ</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_in</span><span class="o">+</span><span class="n">biais</span><span class="p">,</span><span class="n">n_out</span><span class="p">))</span>
    <span class="p">}</span>
    <span class="n">_weight</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;Sigmoid&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;Tanh&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s2">&quot;ReLU&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="o">**</span><span class="mf">.5</span>

    <span class="p">}</span>
    <span class="n">default_values</span> <span class="o">=</span> <span class="p">{</span>

        <span class="s2">&quot;Uniform&quot;</span> <span class="p">:</span> <span class="k">lambda</span> <span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span> <span class="p">:</span> <span class="p">(</span><span class="mi">6</span><span class="o">/</span><span class="p">(</span><span class="n">n_in</span><span class="o">+</span><span class="n">n_out</span><span class="p">))</span><span class="o">**</span><span class="mf">.5</span><span class="p">,</span>
        <span class="s2">&quot;Normal&quot;</span> <span class="p">:</span> <span class="k">lambda</span> <span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span> <span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">n_in</span><span class="o">+</span><span class="n">n_out</span><span class="p">))</span><span class="o">**</span><span class="mf">.5</span><span class="p">,</span>

    <span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weight</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">XavierHe</span><span class="o">.</span><span class="n">_weight</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">param</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">XavierHe</span><span class="o">.</span><span class="n">default_values</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">distribution</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">init_func</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">gen</span> <span class="o">=</span> <span class="n">XavierHe</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">distribution</span><span class="p">)</span>
        <span class="n">eq</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span><span class="p">,</span><span class="n">biais</span><span class="o">=</span><span class="kc">True</span> <span class="p">:</span> <span class="n">gen</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span><span class="p">),</span><span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span><span class="p">,</span><span class="n">biais</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eq</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">distribution</span><span class="p">:</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;Uniform&quot;</span><span class="p">,</span><span class="s2">&quot;Normal&quot;</span><span class="p">],</span><span class="n">activation</span><span class="p">:</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">,</span><span class="s2">&quot;Tanh&quot;</span><span class="p">,</span><span class="s2">&quot;ReLU&quot;</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution</span> <span class="o">=</span> <span class="n">distribution</span>        
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>


</div>



<div class="doc doc-object doc-function">



<h2 id="neural_net.init_funcs.XHReluuniform" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">XHReluuniform</span><span class="p">(</span><span class="n">n_in</span><span class="p">,</span> <span class="n">n_out</span><span class="p">,</span> <span class="n">biais</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>A function representing weight initialization using Xavier (Glorot) initialization
for Rectified linear unit(RELU) activation functions.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>n_in</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Number of input units.</p>
              </div>
            </li>
            <li>
              <b><code>n_out</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Number of output units (neurons).</p>
              </div>
            </li>
            <li>
              <b><code>biais</code></b>
                  (<code>bool</code>, default:
                      <code>True</code>
)
              –
              <div class="doc-md-description">
                <p>if True adds biais weights</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray : array of random values</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\init_funcs.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">XHReluuniform</span><span class="p">(</span><span class="n">n_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span><span class="n">biais</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A function representing weight initialization using Xavier (Glorot) initialization</span>
<span class="sd">    for Rectified linear unit(RELU) activation functions.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_in (int): Number of input units.</span>
<span class="sd">        n_out (int): Number of output units (neurons).</span>
<span class="sd">        biais (bool): if True adds biais weights</span>

<span class="sd">    returns:</span>
<span class="sd">        numpy.ndarray : array of random values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">r</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mf">.5</span><span class="o">*</span><span class="p">(</span><span class="mi">6</span><span class="o">/</span><span class="p">(</span><span class="n">n_in</span><span class="o">+</span><span class="n">n_out</span><span class="p">))</span><span class="o">**</span><span class="mf">.5</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="n">r</span><span class="p">,</span><span class="n">high</span><span class="o">=</span><span class="n">r</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_in</span><span class="o">+</span><span class="n">biais</span><span class="p">,</span><span class="n">n_out</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="neural_net.init_funcs.XHsigmoiduniform" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">XHsigmoiduniform</span><span class="p">(</span><span class="n">n_in</span><span class="p">,</span> <span class="n">n_out</span><span class="p">,</span> <span class="n">biais</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>A function representing weight initialization using Xavier (Glorot) initialization
for sigmoid activation functions.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>n_in</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Number of input units.</p>
              </div>
            </li>
            <li>
              <b><code>n_out</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Number of output units (neurons).</p>
              </div>
            </li>
            <li>
              <b><code>biais</code></b>
                  (<code>bool</code>)
              –
              <div class="doc-md-description">
                <p>if True adds biais weights</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray : array of random values</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\init_funcs.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">XHsigmoiduniform</span><span class="p">(</span><span class="n">n_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span><span class="n">biais</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A function representing weight initialization using Xavier (Glorot) initialization</span>
<span class="sd">    for sigmoid activation functions.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        n_in (int): Number of input units.</span>
<span class="sd">        n_out (int): Number of output units (neurons).</span>
<span class="sd">        biais (bool): if True adds biais weights</span>

<span class="sd">    returns:</span>
<span class="sd">        numpy.ndarray : array of random values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">r</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="o">/</span><span class="p">(</span><span class="n">n_in</span><span class="o">+</span><span class="n">n_out</span><span class="p">))</span><span class="o">**</span><span class="mf">.5</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="n">r</span><span class="p">,</span><span class="n">high</span><span class="o">=</span><span class="n">r</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_in</span><span class="o">+</span><span class="n">biais</span><span class="p">,</span><span class="n">n_out</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="neural_net.init_funcs.zeros" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">zeros</span><span class="p">(</span><span class="n">n_in</span><span class="p">,</span> <span class="n">n_out</span><span class="p">,</span> <span class="n">biais</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Initializes a weight matrix with zeros.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>n_in</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Number of input units.</p>
              </div>
            </li>
            <li>
              <b><code>n_out</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Number of output units.</p>
              </div>
            </li>
            <li>
              <b><code>biais</code></b>
                  (<code>bool</code>, default:
                      <code>True</code>
)
              –
              <div class="doc-md-description">
                <p>if True adds biais weights</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Weight matrix of shape (n_in + 1, n_out).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\init_funcs.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">zeros</span><span class="p">(</span><span class="n">n_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span><span class="n">biais</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a weight matrix with zeros.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_in (int): Number of input units.</span>
<span class="sd">        n_out (int): Number of output units.</span>
<span class="sd">        biais (bool): if True adds biais weights</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Weight matrix of shape (n_in + 1, n_out).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_in</span><span class="o">+</span><span class="n">biais</span><span class="p">,</span><span class="n">n_out</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div><h2 id="section-5-cost-functions">Section 5. cost functions</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.cost"></a>
  <div class="doc doc-contents first">
  
      <p>This module provides classes for several types of cost functions</p>
<ul>
<li><code>binaryCrossEntropy</code> </li>
<li><code>CrossEntropy</code> </li>
<li><code>MSE</code></li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.cost.BinaryCrossEntropy" class="doc doc-heading">
          <code>BinaryCrossEntropy</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Cost" href="#neural_net.model.Cost">Cost</a></code></p>

  
      <p>Binary Cross-Entropy Loss.
<script type="math/tex; mode=display">
\mathrm{\mathit{Binary\ Cross\ Entropy}}(p, y) = \begin{cases}
-\log(p) & \text{if } y = 1, \\
-\log(1-p) & \text{otherwise.}
\end{cases}
</script>
<br />
This class computes the binary cross-entropy loss between true labels (y) and predicted probabilities (p).</p>



  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><span title="neural_net.cost.BinaryCrossEntropy.- compute">- compute</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>numpy.ndarray, p: numpy.ndarray) -&gt; float:
Computes the binary cross-entropy loss.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><span title="neural_net.cost.BinaryCrossEntropy.- pr">- pr</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>numpy.ndarray, p: numpy.ndarray) -&gt; numpy.ndarray:
Computes the derivative function values.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

<details class="example" open>
  <summary>Example</summary>
  <pre><code class="language-python">        &gt;&gt;&gt; y_true = numpy.array([[0], [1], [1], [0]])
        &gt;&gt;&gt; predicted_probs = numpy.array([[0.2], [0.8], [0.6], [0.3]])
        &gt;&gt;&gt; bce_loss = binaryCrossEntropy()
        &gt;&gt;&gt; loss_value = bce_loss.compute(y_true, predicted_probs)
        &gt;&gt;&gt; print(f&quot;Binary Cross-Entropy Loss: {loss_value:.4f}&quot;)
        Binary Cross-Entropy Loss: 0.3284
        &gt;&gt;&gt; derivative_values = bce_loss.pr()
        &gt;&gt;&gt; print(f&quot;Derivative Function Values: {derivative_values}&quot;)
        Derivative Function Values: [ 1.25       -1.25       -1.66666667  1.42857143]
</code></pre>
</details>
            <details class="quote">
              <summary>Source code in <code>neural_net\cost.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BinaryCrossEntropy</span><span class="p">(</span><span class="n">Cost</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Binary Cross-Entropy Loss.</span>
<span class="sd">    $$</span>
<span class="sd">    \mathrm{\mathit{Binary\ Cross\ Entropy}}(p, y) = \begin{cases}</span>
<span class="sd">    -\log(p) &amp; \text{if } y = 1, \\</span>
<span class="sd">    -\log(1-p) &amp; \text{otherwise.}</span>
<span class="sd">    \end{cases}</span>
<span class="sd">    $$    </span>
<span class="sd">    This class computes the binary cross-entropy loss between true labels (y) and predicted probabilities (p).</span>

<span class="sd">    Methods:</span>
<span class="sd">        - compute(y: numpy.ndarray, p: numpy.ndarray) -&gt; float:</span>
<span class="sd">            Computes the binary cross-entropy loss.</span>

<span class="sd">        - pr(y: numpy.ndarray, p: numpy.ndarray) -&gt; numpy.ndarray:</span>
<span class="sd">            Computes the derivative function values.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">                &gt;&gt;&gt; y_true = numpy.array([[0], [1], [1], [0]])</span>
<span class="sd">                &gt;&gt;&gt; predicted_probs = numpy.array([[0.2], [0.8], [0.6], [0.3]])</span>
<span class="sd">                &gt;&gt;&gt; bce_loss = binaryCrossEntropy()</span>
<span class="sd">                &gt;&gt;&gt; loss_value = bce_loss.compute(y_true, predicted_probs)</span>
<span class="sd">                &gt;&gt;&gt; print(f&quot;Binary Cross-Entropy Loss: {loss_value:.4f}&quot;)</span>
<span class="sd">                Binary Cross-Entropy Loss: 0.3284</span>
<span class="sd">                &gt;&gt;&gt; derivative_values = bce_loss.pr()</span>
<span class="sd">                &gt;&gt;&gt; print(f&quot;Derivative Function Values: {derivative_values}&quot;)</span>
<span class="sd">                Derivative Function Values: [ 1.25       -1.25       -1.66666667  1.42857143]</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Architecture_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative function values  with respet to p.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative function values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">clip</span> <span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the binary cross-entropy loss.</span>

<span class="sd">        Args:</span>
<span class="sd">            y (numpy.ndarray): True labels (0 or 1).</span>
<span class="sd">            p (numpy.ndarray): Predicted probabilities (between 0 and 1).</span>
<span class="sd">            clip (bool): Whether or not to clip predicted values see method clip</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: Binary cross-entropy loss value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
        <span class="k">if</span> <span class="n">clip</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">clip</span><span class="p">()</span>
        <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.cost.BinaryCrossEntropy.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">clip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the binary cross-entropy loss.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>y</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>True labels (0 or 1).</p>
              </div>
            </li>
            <li>
              <b><code>p</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Predicted probabilities (between 0 and 1).</p>
              </div>
            </li>
            <li>
              <b><code>clip</code></b>
                  (<code>bool</code>, default:
                      <code>True</code>
)
              –
              <div class="doc-md-description">
                <p>Whether or not to clip predicted values see method clip</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>float</code></b>(                <code>float</code>
)            –
            <div class="doc-md-description">
              <p>Binary cross-entropy loss value.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\cost.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">clip</span> <span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the binary cross-entropy loss.</span>

<span class="sd">    Args:</span>
<span class="sd">        y (numpy.ndarray): True labels (0 or 1).</span>
<span class="sd">        p (numpy.ndarray): Predicted probabilities (between 0 and 1).</span>
<span class="sd">        clip (bool): Whether or not to clip predicted values see method clip</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: Binary cross-entropy loss value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
    <span class="k">if</span> <span class="n">clip</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">clip</span><span class="p">()</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.cost.BinaryCrossEntropy.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative function values  with respet to p.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative function values.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\cost.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative function values  with respet to p.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative function values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.cost.CrossEntropy" class="doc doc-heading">
          <code>CrossEntropy</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Cost" href="#neural_net.model.Cost">Cost</a></code></p>

  
      <p>Cross-Entropy Loss.</p>
<p>This class computes the cross-entropy loss between true labels (y) and predicted probabilities (p).
<script type="math/tex; mode=display">
Cross\ Entropy(p,y) = -\sum _{i}\sum _{j}y_{ij}\log p_{ij}\ 
</script>
</p>



  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><span title="neural_net.cost.CrossEntropy.- compute">- compute</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>numpy.ndarray, p: numpy.ndarray) -&gt; float:
Computes the cross-entropy loss.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><span title="neural_net.cost.CrossEntropy.- pr">- pr</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the derivative function values.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

<details class="example" open>
  <summary>Example</summary>
  <pre><code class="language-python">        &gt;&gt;&gt; y_true = numpy.array([[1, 0, 0],
        ...        [0, 1, 0],
        ...        [0, 0, 1],
        ...        [0, 1, 0],
        ...        [1, 0, 0]])
        &gt;&gt;&gt; predicted_probs = numpy.array([[0, 0.6, 0.3],
        ...                                [0.4, 0.2, 0.4],
        ...                                [0.2, 0.3, 0.5],
        ...                                [0.5, 0.1, 0.4],
        ...                                [0.3, 0.4, 0.3]])
        &gt;&gt;&gt; ce_loss = CrossEntropy()
        &gt;&gt;&gt; loss_value = ce_loss.compute(y_true, predicted_probs)
        &gt;&gt;&gt; print(f&quot;Cross-Entropy Loss: {loss_value:.4f}&quot;)
        Cross-Entropy Loss: 1.7915
        &gt;&gt;&gt; derivative_values = ce_loss.pr()
        &gt;&gt;&gt; print(f&quot;Derivative Function Values: {derivative_values}&quot;)
        Derivative Function Values: array([[-1.00000000e+07,  2.50000000e+00,  1.42857143e+00],
       [ 1.66666667e+00, -5.00000000e+00,  1.66666667e+00],
       [ 1.25000000e+00,  1.42857143e+00, -2.00000000e+00],
       [ 2.00000000e+00, -1.00000000e+01,  1.66666667e+00],
       [-3.33333333e+00,  1.66666667e+00,  1.42857143e+00]])
</code></pre>
</details>
            <details class="quote">
              <summary>Source code in <code>neural_net\cost.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CrossEntropy</span><span class="p">(</span><span class="n">Cost</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Cross-Entropy Loss.</span>

<span class="sd">    This class computes the cross-entropy loss between true labels (y) and predicted probabilities (p).</span>
<span class="sd">    $$</span>
<span class="sd">    Cross\ Entropy(p,y) = -\sum _{i}\sum _{j}y_{ij}\log p_{ij}\ </span>
<span class="sd">    $$</span>

<span class="sd">    Methods:</span>
<span class="sd">        - compute(y: numpy.ndarray, p: numpy.ndarray) -&gt; float:</span>
<span class="sd">            Computes the cross-entropy loss.</span>

<span class="sd">        - pr() -&gt; numpy.ndarray:</span>
<span class="sd">            Computes the derivative function values.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">                &gt;&gt;&gt; y_true = numpy.array([[1, 0, 0],</span>
<span class="sd">                ...        [0, 1, 0],</span>
<span class="sd">                ...        [0, 0, 1],</span>
<span class="sd">                ...        [0, 1, 0],</span>
<span class="sd">                ...        [1, 0, 0]])</span>
<span class="sd">                &gt;&gt;&gt; predicted_probs = numpy.array([[0, 0.6, 0.3],</span>
<span class="sd">                ...                                [0.4, 0.2, 0.4],</span>
<span class="sd">                ...                                [0.2, 0.3, 0.5],</span>
<span class="sd">                ...                                [0.5, 0.1, 0.4],</span>
<span class="sd">                ...                                [0.3, 0.4, 0.3]])</span>
<span class="sd">                &gt;&gt;&gt; ce_loss = CrossEntropy()</span>
<span class="sd">                &gt;&gt;&gt; loss_value = ce_loss.compute(y_true, predicted_probs)</span>
<span class="sd">                &gt;&gt;&gt; print(f&quot;Cross-Entropy Loss: {loss_value:.4f}&quot;)</span>
<span class="sd">                Cross-Entropy Loss: 1.7915</span>
<span class="sd">                &gt;&gt;&gt; derivative_values = ce_loss.pr()</span>
<span class="sd">                &gt;&gt;&gt; print(f&quot;Derivative Function Values: {derivative_values}&quot;)</span>
<span class="sd">                Derivative Function Values: array([[-1.00000000e+07,  2.50000000e+00,  1.42857143e+00],</span>
<span class="sd">               [ 1.66666667e+00, -5.00000000e+00,  1.66666667e+00],</span>
<span class="sd">               [ 1.25000000e+00,  1.42857143e+00, -2.00000000e+00],</span>
<span class="sd">               [ 2.00000000e+00, -1.00000000e+01,  1.66666667e+00],</span>
<span class="sd">               [-3.33333333e+00,  1.66666667e+00,  1.42857143e+00]])</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Architecture_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative function values  with respet to p .</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative function values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">left</span>  <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
        <span class="c1">#right = left.sum(axis=1,keepdims=True)*(f:=((1-self.y)/(1-self.p)))/f.sum(axis=1,keepdims=True)</span>
        <span class="n">right</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">left</span> <span class="o">-</span> <span class="n">right</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">clip</span> <span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the Cross-entropy loss.</span>

<span class="sd">        Args:</span>
<span class="sd">            y (numpy.ndarray): True labels (0 or 1).</span>
<span class="sd">            p (numpy.ndarray): Predicted probabilities (between 0 and 1).</span>
<span class="sd">            clip (bool): Whether or not to clip predicted values see method clip.</span>


<span class="sd">        Returns:</span>
<span class="sd">            float: Cross-entropy loss value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
        <span class="k">if</span> <span class="n">clip</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">clip</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.cost.CrossEntropy.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">clip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the Cross-entropy loss.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>y</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>True labels (0 or 1).</p>
              </div>
            </li>
            <li>
              <b><code>p</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Predicted probabilities (between 0 and 1).</p>
              </div>
            </li>
            <li>
              <b><code>clip</code></b>
                  (<code>bool</code>, default:
                      <code>True</code>
)
              –
              <div class="doc-md-description">
                <p>Whether or not to clip predicted values see method clip.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>float</code></b>(                <code>float</code>
)            –
            <div class="doc-md-description">
              <p>Cross-entropy loss value.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\cost.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">clip</span> <span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the Cross-entropy loss.</span>

<span class="sd">    Args:</span>
<span class="sd">        y (numpy.ndarray): True labels (0 or 1).</span>
<span class="sd">        p (numpy.ndarray): Predicted probabilities (between 0 and 1).</span>
<span class="sd">        clip (bool): Whether or not to clip predicted values see method clip.</span>


<span class="sd">    Returns:</span>
<span class="sd">        float: Cross-entropy loss value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
    <span class="k">if</span> <span class="n">clip</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">clip</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.cost.CrossEntropy.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative function values  with respet to p .</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative function values.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\cost.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative function values  with respet to p .</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative function values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">left</span>  <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    <span class="c1">#right = left.sum(axis=1,keepdims=True)*(f:=((1-self.y)/(1-self.p)))/f.sum(axis=1,keepdims=True)</span>
    <span class="n">right</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">left</span> <span class="o">-</span> <span class="n">right</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.cost.MSE" class="doc doc-heading">
          <code>MSE</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Cost" href="#neural_net.model.Cost">Cost</a></code></p>

  
      <p>Mean Squared Error (MSE) Loss.</p>
<p>This class computes the mean squared error loss between true labels (y) and predicted values (p).</p>
<p>
<script type="math/tex; mode=display">
\displaystyle \operatorname {MSE} ={\frac {1}{n}}\sum _{i=1}^{n}\left(y_{i}-{\hat {y_{i}}}\right)^{2}
</script>
</p>



  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><span title="neural_net.cost.MSE.- compute">- compute</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>numpy.ndarray, p: numpy.ndarray) -&gt; float:
Computes the mean squared error loss.</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><span title="neural_net.cost.MSE.- pr">- pr</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the derivative function values.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

<details class="example" open>
  <summary>Example</summary>
  <pre><code class="language-python">        &gt;&gt;&gt; y_true = numpy.array([[2.0], [3.5], [5.0], [4.2]])
        &gt;&gt;&gt; predicted_values = numpy.array([[1.8], [3.2], [4.8], [4.0]])
        &gt;&gt;&gt; mse_loss = MSE()
        &gt;&gt;&gt; loss_value = mse_loss.compute(y_true, predicted_values)
        &gt;&gt;&gt; print(f&quot;Mean Squared Error Loss: {loss_value:.4f}&quot;)
        Mean Squared Error Loss:  0.0525
        &gt;&gt;&gt; derivative_values = mse_loss.pr()
        &gt;&gt;&gt; print(f&quot;Derivative Function Values: {derivative_values}&quot;)
        Derivative Function Values: [[-0.4]
        [-0.6]
        [-0.4]
        [-0.4]]
</code></pre>
</details>
            <details class="quote">
              <summary>Source code in <code>neural_net\cost.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MSE</span><span class="p">(</span><span class="n">Cost</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mean Squared Error (MSE) Loss.</span>

<span class="sd">    This class computes the mean squared error loss between true labels (y) and predicted values (p).</span>

<span class="sd">    $$</span>
<span class="sd">    \displaystyle \operatorname {MSE} ={\frac {1}{n}}\sum _{i=1}^{n}\left(y_{i}-{\hat {y_{i}}}\right)^{2}</span>
<span class="sd">    $$</span>

<span class="sd">    Methods:</span>
<span class="sd">        - compute(y: numpy.ndarray, p: numpy.ndarray) -&gt; float:</span>
<span class="sd">            Computes the mean squared error loss.</span>

<span class="sd">        - pr() -&gt; numpy.ndarray:</span>
<span class="sd">            Computes the derivative function values.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">                &gt;&gt;&gt; y_true = numpy.array([[2.0], [3.5], [5.0], [4.2]])</span>
<span class="sd">                &gt;&gt;&gt; predicted_values = numpy.array([[1.8], [3.2], [4.8], [4.0]])</span>
<span class="sd">                &gt;&gt;&gt; mse_loss = MSE()</span>
<span class="sd">                &gt;&gt;&gt; loss_value = mse_loss.compute(y_true, predicted_values)</span>
<span class="sd">                &gt;&gt;&gt; print(f&quot;Mean Squared Error Loss: {loss_value:.4f}&quot;)</span>
<span class="sd">                Mean Squared Error Loss:  0.0525</span>
<span class="sd">                &gt;&gt;&gt; derivative_values = mse_loss.pr()</span>
<span class="sd">                &gt;&gt;&gt; print(f&quot;Derivative Function Values: {derivative_values}&quot;)</span>
<span class="sd">                Derivative Function Values: [[-0.4]</span>
<span class="sd">                [-0.6]</span>
<span class="sd">                [-0.4]</span>
<span class="sd">                [-0.4]]</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span> 
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Architecture_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the derivative function values  with respet to p .</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray: Derivative function values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the mean squared error loss.</span>

<span class="sd">        Args:</span>
<span class="sd">            y (numpy.ndarray): True labels (ground truth).</span>
<span class="sd">            p (numpy.ndarray): Predicted values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: Mean squared error loss value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
        <span class="k">return</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.cost.MSE.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the mean squared error loss.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>y</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>True labels (ground truth).</p>
              </div>
            </li>
            <li>
              <b><code>p</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Predicted values.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>float</code></b>(                <code>float</code>
)            –
            <div class="doc-md-description">
              <p>Mean squared error loss value.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\cost.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the mean squared error loss.</span>

<span class="sd">    Args:</span>
<span class="sd">        y (numpy.ndarray): True labels (ground truth).</span>
<span class="sd">        p (numpy.ndarray): Predicted values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: Mean squared error loss value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
    <span class="k">return</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.cost.MSE.pr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">pr</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the derivative function values  with respet to p .</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Derivative function values.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\cost.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the derivative function values  with respet to p .</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Derivative function values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div><h2 id="section-6-metrics">Section 6. metrics</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.metrics"></a>
  <div class="doc doc-contents first">
  
      <p>This module provides metrics classes</p>
<ul>
<li><code>accuracy</code> </li>
<li><code>MAE</code></li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.metrics.MAE" class="doc doc-heading">
          <code>MAE</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Metrics" href="#neural_net.model.Metrics">Metrics</a></code></p>

  
      <p>Mean Absolute Error (MAE) .</p>
<p>This class computes the mean absolute error loss between true labels (y) and predicted values (p).</p>
<p>
<script type="math/tex; mode=display">
\displaystyle \operatorname {MAE} ={\frac {1}{n}}\sum _{i=1}^{n}\left|y_{i}-{\hat {y_{i}}}\right|
</script>
</p>



  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><span title="neural_net.metrics.MAE.- compute">- compute</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>numpy.ndarray, p: numpy.ndarray) -&gt; float:
Computes the mean absolute error.</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

<details class="example" open>
  <summary>Example</summary>
  <pre><code class="language-python">        &gt;&gt;&gt; y_true = numpy.array([[2.0], [3.5], [5.0], [4.2]])
        &gt;&gt;&gt; predicted_values = numpy.array([[1.8], [3.2], [4.8], [4.0]])
        &gt;&gt;&gt; mae_loss = MAE()
        &gt;&gt;&gt; loss_value = mae_loss.compute(y_true, predicted_values)
        &gt;&gt;&gt; print(f&quot;Mean Squared Error Loss: {loss_value:.4f}&quot;)
        Mean Squared Error Loss:  0.0525
        &gt;&gt;&gt; derivative_values = mse_loss.pr()
        &gt;&gt;&gt; print(f&quot;Derivative Function Values: {derivative_values}&quot;)
        Derivative Function Values: [[-0.4]
        [-0.6]
        [-0.4]
        [-0.4]]
</code></pre>
</details>
            <details class="quote">
              <summary>Source code in <code>neural_net\metrics.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MAE</span><span class="p">(</span><span class="n">Metrics</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mean Absolute Error (MAE) .</span>

<span class="sd">    This class computes the mean absolute error loss between true labels (y) and predicted values (p).</span>

<span class="sd">    $$</span>
<span class="sd">    \displaystyle \operatorname {MAE} ={\frac {1}{n}}\sum _{i=1}^{n}\left|y_{i}-{\hat {y_{i}}}\right|</span>
<span class="sd">    $$</span>

<span class="sd">    Methods:</span>
<span class="sd">        - compute(y: numpy.ndarray, p: numpy.ndarray) -&gt; float:</span>
<span class="sd">            Computes the mean absolute error.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">                &gt;&gt;&gt; y_true = numpy.array([[2.0], [3.5], [5.0], [4.2]])</span>
<span class="sd">                &gt;&gt;&gt; predicted_values = numpy.array([[1.8], [3.2], [4.8], [4.0]])</span>
<span class="sd">                &gt;&gt;&gt; mae_loss = MAE()</span>
<span class="sd">                &gt;&gt;&gt; loss_value = mae_loss.compute(y_true, predicted_values)</span>
<span class="sd">                &gt;&gt;&gt; print(f&quot;Mean Squared Error Loss: {loss_value:.4f}&quot;)</span>
<span class="sd">                Mean Squared Error Loss:  0.0525</span>
<span class="sd">                &gt;&gt;&gt; derivative_values = mse_loss.pr()</span>
<span class="sd">                &gt;&gt;&gt; print(f&quot;Derivative Function Values: {derivative_values}&quot;)</span>
<span class="sd">                Derivative Function Values: [[-0.4]</span>
<span class="sd">                [-0.6]</span>
<span class="sd">                [-0.4]</span>
<span class="sd">                [-0.4]]</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span> 
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Architecture_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="nb">locals</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the mean absolute error loss.</span>

<span class="sd">        Args:</span>
<span class="sd">            y (numpy.ndarray): True labels (ground truth).</span>
<span class="sd">            p (numpy.ndarray): Predicted values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: Mean absolute error value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.metrics.MAE.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the mean absolute error loss.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>y</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>True labels (ground truth).</p>
              </div>
            </li>
            <li>
              <b><code>p</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Predicted values.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>float</code></b>(                <code>float</code>
)            –
            <div class="doc-md-description">
              <p>Mean absolute error value.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\metrics.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the mean absolute error loss.</span>

<span class="sd">    Args:</span>
<span class="sd">        y (numpy.ndarray): True labels (ground truth).</span>
<span class="sd">        p (numpy.ndarray): Predicted values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: Mean absolute error value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.metrics.accuracy" class="doc doc-heading">
          <code>accuracy</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Metrics" href="#neural_net.model.Metrics">Metrics</a></code></p>

  
      <p>Calculates the accuracy metric for binary or multiclass classification tasks.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>threshold</code></b>
                  (<code>float</code>, default:
                      <code>0.5</code>
)
              –
              <div class="doc-md-description">
                <p>Threshold value for binary classification. Defaults to 0.5.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>threshold</code></b>
                  (<code>float</code>)
              –
              <div class="doc-md-description">
                <p>The threshold value used for binary classification.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.metrics.accuracy.compute" href="#neural_net.metrics.accuracy.compute">compute</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Computes the accuracy score based on true labels (y) and predicted probabilities (p).</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>
      <p>Example:</p>
<pre><code class="language-python">        &gt;&gt;&gt; acc = accuracy(threshold=0.6)
        &gt;&gt;&gt; y_true = numpy.array([[1], [0], [1], [0]])
        &gt;&gt;&gt; y_pred = numpy.array([[0.8], [0.3], [0.9], [0.5]])
        &gt;&gt;&gt; val = acc.compute(y_true, y_pred)
        &gt;&gt;&gt; print(f&quot;Accuracy: {val:.4f}&quot;)
        Accuracy: 1.0000
        &gt;&gt;&gt; y_true_multiclass = numpy.array([[0, 0, 1],
        ...        [0, 1, 0],
        ...        [1, 0, 0],
        ...        [0, 0, 1],
        ...        [0, 1, 0],
        ...        [1, 0, 0],
        ...        [0, 1, 0],
        ...        [0, 0, 1]])
        &gt;&gt;&gt; y_pred_multiclass = numpy.array([
        ...     [0.1, 0.2, 0.7],  # Predicted probabilities for class 0
        ...     [0.6, 0.3, 0.1],  # Predicted probabilities for class 1
        ...     [0.8, 0.1, 0.1],  # Predicted probabilities for class 2
        ...     [0.2, 0.3, 0.5],
        ...     [0.4, 0.4, 0.2],
        ...     [0.7, 0.2, 0.1],
        ...     [0.3, 0.4, 0.3],
        ...     [0.1, 0.2, 0.7]
        ... ])
        &gt;&gt;&gt; model_multiclass = accuracy(threshold=0.5)
        &gt;&gt;&gt; acc_multiclass = model_multiclass.compute(y_true_multiclass, y_pred_multiclass)
        &gt;&gt;&gt; print(f&quot;Accuracy (multiclass): {acc_multiclass:.4f}&quot;)
        Accuracy (multiclass): 0.7500
</code></pre>

            <details class="quote">
              <summary>Source code in <code>neural_net\metrics.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">accuracy</span><span class="p">(</span><span class="n">Metrics</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the accuracy metric for binary or multiclass classification tasks.</span>

<span class="sd">    Args:</span>
<span class="sd">        threshold (float, optional): Threshold value for binary classification. Defaults to 0.5.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        threshold (float): The threshold value used for binary classification.</span>

<span class="sd">    Methods:</span>
<span class="sd">        compute(y, p):</span>
<span class="sd">            Computes the accuracy score based on true labels (y) and predicted probabilities (p).</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">            &gt;&gt;&gt; acc = accuracy(threshold=0.6)</span>
<span class="sd">            &gt;&gt;&gt; y_true = numpy.array([[1], [0], [1], [0]])</span>
<span class="sd">            &gt;&gt;&gt; y_pred = numpy.array([[0.8], [0.3], [0.9], [0.5]])</span>
<span class="sd">            &gt;&gt;&gt; val = acc.compute(y_true, y_pred)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Accuracy: {val:.4f}&quot;)</span>
<span class="sd">            Accuracy: 1.0000</span>
<span class="sd">            &gt;&gt;&gt; y_true_multiclass = numpy.array([[0, 0, 1],</span>
<span class="sd">            ...        [0, 1, 0],</span>
<span class="sd">            ...        [1, 0, 0],</span>
<span class="sd">            ...        [0, 0, 1],</span>
<span class="sd">            ...        [0, 1, 0],</span>
<span class="sd">            ...        [1, 0, 0],</span>
<span class="sd">            ...        [0, 1, 0],</span>
<span class="sd">            ...        [0, 0, 1]])</span>
<span class="sd">            &gt;&gt;&gt; y_pred_multiclass = numpy.array([</span>
<span class="sd">            ...     [0.1, 0.2, 0.7],  # Predicted probabilities for class 0</span>
<span class="sd">            ...     [0.6, 0.3, 0.1],  # Predicted probabilities for class 1</span>
<span class="sd">            ...     [0.8, 0.1, 0.1],  # Predicted probabilities for class 2</span>
<span class="sd">            ...     [0.2, 0.3, 0.5],</span>
<span class="sd">            ...     [0.4, 0.4, 0.2],</span>
<span class="sd">            ...     [0.7, 0.2, 0.1],</span>
<span class="sd">            ...     [0.3, 0.4, 0.3],</span>
<span class="sd">            ...     [0.1, 0.2, 0.7]</span>
<span class="sd">            ... ])</span>
<span class="sd">            &gt;&gt;&gt; model_multiclass = accuracy(threshold=0.5)</span>
<span class="sd">            &gt;&gt;&gt; acc_multiclass = model_multiclass.compute(y_true_multiclass, y_pred_multiclass)</span>
<span class="sd">            &gt;&gt;&gt; print(f&quot;Accuracy (multiclass): {acc_multiclass:.4f}&quot;)</span>
<span class="sd">            Accuracy (multiclass): 0.7500</span>
<span class="sd">    ```</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">threshold</span> <span class="o">=</span> <span class="mf">.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the accuracy metric.</span>

<span class="sd">        Args:</span>
<span class="sd">            threshold (float, optional): Threshold value for binary classification. Defaults to 0.5.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the accuracy of predictions.</span>

<span class="sd">        Args:</span>
<span class="sd">            y (numpy.ndarray): True labels (ground truth).</span>
<span class="sd">            p (numpy.ndarray): Predicted values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: accuracy value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span><span class="o">&gt;</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span> <span class="o">+</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
        <span class="k">return</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">==</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">))</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.metrics.accuracy.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initializes the accuracy metric.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>threshold</code></b>
                  (<code>float</code>, default:
                      <code>0.5</code>
)
              –
              <div class="doc-md-description">
                <p>Threshold value for binary classification. Defaults to 0.5.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\metrics.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">threshold</span> <span class="o">=</span> <span class="mf">.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the accuracy metric.</span>

<span class="sd">    Args:</span>
<span class="sd">        threshold (float, optional): Threshold value for binary classification. Defaults to 0.5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.metrics.accuracy.compute" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the accuracy of predictions.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>y</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>True labels (ground truth).</p>
              </div>
            </li>
            <li>
              <b><code>p</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Predicted values.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>float</code></b>(                <code>float</code>
)            –
            <div class="doc-md-description">
              <p>accuracy value.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\metrics.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">p</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the accuracy of predictions.</span>

<span class="sd">    Args:</span>
<span class="sd">        y (numpy.ndarray): True labels (ground truth).</span>
<span class="sd">        p (numpy.ndarray): Predicted values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: accuracy value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span><span class="o">&gt;</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span> <span class="o">+</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span><span class="n">p</span>
    <span class="k">return</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">==</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">))</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div><h2 id="section-7-database-management">Section 7. database management</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.db"></a>
  <div class="doc doc-contents first">
  
      <p>This module provides sqlalchemy orm tables and utility objects</p>
<ul>
<li><code>DefaultTable</code> - generic table template</li>
<li><code>Architecture</code> - Architecture table</li>
<li><code>Layer</code> - layer table<ul>
<li><code>Neurons</code> - neurons table</li>
<li><code>Cost</code> - cost table</li>
<li><code>Weight</code> - weight table</li>
</ul>
</li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.db.DBmanager" class="doc doc-heading">
          <code>DBmanager</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Manages database connections and sessions using SQLAlchemy.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>session</code></b>
                  (<code>Session</code>)
              –
              <div class="doc-md-description">
                <p>SQLAlchemy session for database operations.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.db.DBmanager.__start" href="#neural_net.db.DBmanager.__start">__start</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>str=None)-&gt; None:
Starts a session</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>
      <pre><code>add_table(table: DefaultTable) -&gt; None:
    Adds a table instance to the current session.
commit() -&gt; None:
    Commits changes to the session.
</code></pre>

            <details class="quote">
              <summary>Source code in <code>neural_net\db.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DBmanager</span><span class="p">:</span>
<span class="w">	</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Manages database connections and sessions using SQLAlchemy.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        session (Session): SQLAlchemy session for database operations.</span>

<span class="sd">    Methods:</span>
<span class="sd">		__start(db : str=None)-&gt; None:</span>
<span class="sd">			Starts a session</span>
<span class="sd">        add_table(table: DefaultTable) -&gt; None:</span>
<span class="sd">            Adds a table instance to the current session.</span>
<span class="sd">        commit() -&gt; None:</span>
<span class="sd">            Commits changes to the session.</span>
<span class="sd">    &quot;&quot;&quot;</span>
	<span class="n">engines</span> <span class="o">=</span> <span class="p">{}</span>
	<span class="n">status</span> <span class="o">=</span> <span class="kc">False</span>

	<span class="k">def</span> <span class="nf">__start</span><span class="p">(</span><span class="n">db</span> <span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Starts a session</span>

<span class="sd">		Args:</span>
<span class="sd">       		 db (str, optional): Path to database server or SQLite database file. Defaults to None.</span>

<span class="sd">		&quot;&quot;&quot;</span>
		<span class="n">db_path</span> <span class="o">=</span> <span class="n">db</span> <span class="ow">or</span> <span class="sa">f</span><span class="s1">&#39;sqlite:///</span><span class="si">{</span><span class="n">get_module_path</span><span class="p">([</span><span class="s2">&quot;run&quot;</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;model</span><span class="si">{</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s2">.db&quot;</span><span class="p">])</span><span class="si">}</span><span class="s1">&#39;</span>
		<span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span> <span class="o">=</span><span class="n">db_path</span>
		<span class="n">DBmanager</span><span class="o">.</span><span class="n">engines</span><span class="p">[</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span><span class="p">)</span>
		<span class="n">Base</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">create_all</span><span class="p">(</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">engines</span><span class="p">[</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span><span class="p">])</span>
		<span class="n">Session</span> <span class="o">=</span> <span class="n">sessionmaker</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">engines</span><span class="p">[</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span><span class="p">])</span>
		<span class="n">DBmanager</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">Session</span><span class="p">()</span>

	<span class="k">def</span> <span class="nf">add_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">table</span><span class="p">:</span><span class="n">DefaultTable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Adds a table instance to the current session.</span>

<span class="sd">		Args:</span>
<span class="sd">			table (DefaultTable): An instance of table object</span>

<span class="sd">		&quot;&quot;&quot;</span>
		<span class="k">if</span> <span class="ow">not</span> <span class="n">DBmanager</span><span class="o">.</span><span class="n">status</span> <span class="p">:</span> 
			<span class="n">DBmanager</span><span class="o">.</span><span class="n">_DBmanager__start</span><span class="p">()</span>
			<span class="n">DBmanager</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="kc">True</span>
		<span class="n">DBmanager</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.db.DBmanager.__start" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">__start</span><span class="p">(</span><span class="n">db</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Starts a session</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>db</code></b>
                  (<code>str</code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>Path to database server or SQLite database file. Defaults to None.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\db.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span></pre></div></td><td class="code"><div><pre><span></span><code>	<span class="k">def</span> <span class="nf">__start</span><span class="p">(</span><span class="n">db</span> <span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">		</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">		Starts a session</span>

<span class="sd">		Args:</span>
<span class="sd">       		 db (str, optional): Path to database server or SQLite database file. Defaults to None.</span>

<span class="sd">		&quot;&quot;&quot;</span>
		<span class="n">db_path</span> <span class="o">=</span> <span class="n">db</span> <span class="ow">or</span> <span class="sa">f</span><span class="s1">&#39;sqlite:///</span><span class="si">{</span><span class="n">get_module_path</span><span class="p">([</span><span class="s2">&quot;run&quot;</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;model</span><span class="si">{</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s2">.db&quot;</span><span class="p">])</span><span class="si">}</span><span class="s1">&#39;</span>
		<span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span> <span class="o">=</span><span class="n">db_path</span>
		<span class="n">DBmanager</span><span class="o">.</span><span class="n">engines</span><span class="p">[</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span><span class="p">)</span>
		<span class="n">Base</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">create_all</span><span class="p">(</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">engines</span><span class="p">[</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span><span class="p">])</span>
		<span class="n">Session</span> <span class="o">=</span> <span class="n">sessionmaker</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">engines</span><span class="p">[</span><span class="n">DBmanager</span><span class="o">.</span><span class="n">db_path</span><span class="p">])</span>
		<span class="n">DBmanager</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">Session</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.db.DBmanager.add_table" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">add_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Adds a table instance to the current session.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>table</code></b>
                  (<code><span title="neural_net.db.DefaultTable">DefaultTable</span></code>)
              –
              <div class="doc-md-description">
                <p>An instance of table object</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\db.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">add_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">table</span><span class="p">:</span><span class="n">DefaultTable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">	</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">	Adds a table instance to the current session.</span>

<span class="sd">	Args:</span>
<span class="sd">		table (DefaultTable): An instance of table object</span>

<span class="sd">	&quot;&quot;&quot;</span>
	<span class="k">if</span> <span class="ow">not</span> <span class="n">DBmanager</span><span class="o">.</span><span class="n">status</span> <span class="p">:</span> 
		<span class="n">DBmanager</span><span class="o">.</span><span class="n">_DBmanager__start</span><span class="p">()</span>
		<span class="n">DBmanager</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="kc">True</span>
	<span class="n">DBmanager</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>



<div class="doc doc-object doc-function">



<h2 id="neural_net.db.get_instance" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Returns an SQLAlchemy Table object corresponding to the given table name.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>Table</code></b>(                <code><span title="neural_net.db.DefaultTable">DefaultTable</span></code>
)            –
            <div class="doc-md-description">
              <p>SQLAlchemy Table object corresponding to the specified table name.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\db.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DefaultTable</span><span class="p">:</span>
<span class="w">	</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an SQLAlchemy Table object corresponding to the given table name.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Table: SQLAlchemy Table object corresponding to the specified table name.</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">table</span><span class="p">,</span><span class="n">cols</span> <span class="o">=</span> <span class="n">tables</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">)]</span>
	<span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">}</span>
	<span class="k">return</span> <span class="n">table</span><span class="p">(</span><span class="o">**</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="neural_net.db.update_instance" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">update_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Updates the given instance with the provided keyword arguments.</p>

          <details class="quote">
            <summary>Source code in <code>neural_net\db.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">update_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">	</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">	Updates the given instance with the provided keyword arguments.</span>

<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">_</span><span class="p">,</span><span class="n">cols</span> <span class="o">=</span> <span class="n">tables</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">)]</span>
	<span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
		<span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
			<span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">table</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div><h2 id="section-8-data-preparation-functions">Section 8. data preparation functions</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.pipeline"></a>
  <div class="doc doc-contents first">
  
      <p>This module provides functions for data preparation</p>
<ul>
<li><code>Batch</code> - feed data in chunks</li>
<li><code>shuffle</code> - shuffles train sets</li>
<li><code>onehot</code> - onehot encodes target variables<ul>
<li><code>scaler</code> - scales input features</li>
</ul>
</li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.pipeline.Batch" class="doc doc-heading">
          <code>Batch</code>


</h2>


  <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>neural_net\pipeline.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Batch</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span> <span class="n">y</span> <span class="p">:</span><span class="nb">callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a Batch object.      </span>

<span class="sd">        Args:</span>
<span class="sd">            size (int): Size of each batch.</span>
<span class="sd">            obs (int): Total sample size.</span>
<span class="sd">            X (numpy.ndarray): function providing access to Numpy array containing features.</span>
<span class="sd">            y (numpy.ndarray): function providing access to Numpy array containing target variable.    </span>

<span class="sd">        Returns:</span>
<span class="sd">            None        </span>

<span class="sd">        Example:</span>
<span class="sd">        ```python</span>
<span class="sd">                &gt;&gt;&gt; def get_X():</span>
<span class="sd">                ...     return numpy.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">                &gt;&gt;&gt; def get_y():</span>
<span class="sd">                ...     return numpy.array([[0], [1], [0]])</span>
<span class="sd">                &gt;&gt;&gt; batch_size = 2</span>
<span class="sd">                &gt;&gt;&gt; total_samples = len(X)</span>
<span class="sd">                &gt;&gt;&gt; batch = Batch(size=batch_size, obs=total_samples, X=get_X, y=get_y)</span>
<span class="sd">                &gt;&gt;&gt; for X_batch, y_batch in batch:</span>
<span class="sd">                ...     print(f&quot;Features: {X_batch}, Target: {y_batch}&quot;)</span>
<span class="sd">                Features: [[1 2]</span>
<span class="sd">                [3 4]], Target: [[0]</span>
<span class="sd">                [1]]</span>
<span class="sd">                Features: [[5 6]], Target: [[0]]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">getters</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">ix</span><span class="p">:</span> <span class="p">(</span><span class="n">X</span><span class="p">()[</span><span class="n">ix</span><span class="p">,:],</span><span class="n">y</span><span class="p">()[</span><span class="n">ix</span><span class="p">,:])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getters</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ix</span> <span class="o">=</span> <span class="n">get_ix</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="n">obs</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="o">=</span><span class="mi">0</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="o">&lt;</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ix</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">raise</span> <span class="ne">StopIteration</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.pipeline.Batch.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initialize a Batch object.      </p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>size</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Size of each batch.</p>
              </div>
            </li>
            <li>
              <b><code>obs</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Total sample size.</p>
              </div>
            </li>
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>function providing access to Numpy array containing features.</p>
              </div>
            </li>
            <li>
              <b><code>y</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>function providing access to Numpy array containing target variable.    </p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code>None</code>
            –
            <div class="doc-md-description">
              <p>None        </p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>      <p>Example:</p>
<pre><code class="language-python">        &gt;&gt;&gt; def get_X():
        ...     return numpy.array([[1, 2], [3, 4], [5, 6]])
        &gt;&gt;&gt; def get_y():
        ...     return numpy.array([[0], [1], [0]])
        &gt;&gt;&gt; batch_size = 2
        &gt;&gt;&gt; total_samples = len(X)
        &gt;&gt;&gt; batch = Batch(size=batch_size, obs=total_samples, X=get_X, y=get_y)
        &gt;&gt;&gt; for X_batch, y_batch in batch:
        ...     print(f&quot;Features: {X_batch}, Target: {y_batch}&quot;)
        Features: [[1 2]
        [3 4]], Target: [[0]
        [1]]
        Features: [[5 6]], Target: [[0]]
</code></pre>

          <details class="quote">
            <summary>Source code in <code>neural_net\pipeline.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span> <span class="n">y</span> <span class="p">:</span><span class="nb">callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize a Batch object.      </span>

<span class="sd">    Args:</span>
<span class="sd">        size (int): Size of each batch.</span>
<span class="sd">        obs (int): Total sample size.</span>
<span class="sd">        X (numpy.ndarray): function providing access to Numpy array containing features.</span>
<span class="sd">        y (numpy.ndarray): function providing access to Numpy array containing target variable.    </span>

<span class="sd">    Returns:</span>
<span class="sd">        None        </span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">            &gt;&gt;&gt; def get_X():</span>
<span class="sd">            ...     return numpy.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">            &gt;&gt;&gt; def get_y():</span>
<span class="sd">            ...     return numpy.array([[0], [1], [0]])</span>
<span class="sd">            &gt;&gt;&gt; batch_size = 2</span>
<span class="sd">            &gt;&gt;&gt; total_samples = len(X)</span>
<span class="sd">            &gt;&gt;&gt; batch = Batch(size=batch_size, obs=total_samples, X=get_X, y=get_y)</span>
<span class="sd">            &gt;&gt;&gt; for X_batch, y_batch in batch:</span>
<span class="sd">            ...     print(f&quot;Features: {X_batch}, Target: {y_batch}&quot;)</span>
<span class="sd">            Features: [[1 2]</span>
<span class="sd">            [3 4]], Target: [[0]</span>
<span class="sd">            [1]]</span>
<span class="sd">            Features: [[5 6]], Target: [[0]]</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">getters</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">ix</span><span class="p">:</span> <span class="p">(</span><span class="n">X</span><span class="p">()[</span><span class="n">ix</span><span class="p">,:],</span><span class="n">y</span><span class="p">()[</span><span class="n">ix</span><span class="p">,:])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getters</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ix</span> <span class="o">=</span> <span class="n">get_ix</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="n">obs</span><span class="p">)</span> 
    <span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="o">=</span><span class="mi">0</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>



<div class="doc doc-object doc-function">



<h2 id="neural_net.pipeline.get_ix" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_ix</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Create batch slices for a given sample size and batch size.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>obs</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Total number of samples in the dataset.</p>
              </div>
            </li>
            <li>
              <b><code>size</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>Size of each batch.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code>list[slice]</code>
            –
            <div class="doc-md-description">
              <p>list[slice]: A list of slice objects representing batch indices.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>      <p>Example:</p>
<pre><code class="language-python">        &gt;&gt;&gt; obs = 70  # Total samples
        &gt;&gt;&gt; batch_size = 20
        &gt;&gt;&gt; batch_slices = get_ix(obs, batch_size)
        &gt;&gt;&gt; batch_slices
        [slice(0, 20, None), slice(20, 40, None), slice(40, 60, None), slice(60, 70, None)]
</code></pre>

          <details class="quote">
            <summary>Source code in <code>neural_net\pipeline.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_ix</span><span class="p">(</span><span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span><span class="n">obs</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">slice</span><span class="p">]:</span>  
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create batch slices for a given sample size and batch size.</span>

<span class="sd">    Args:</span>
<span class="sd">        obs (int): Total number of samples in the dataset.</span>
<span class="sd">        size (int): Size of each batch.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list[slice]: A list of slice objects representing batch indices.</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">            &gt;&gt;&gt; obs = 70  # Total samples</span>
<span class="sd">            &gt;&gt;&gt; batch_size = 20</span>
<span class="sd">            &gt;&gt;&gt; batch_slices = get_ix(obs, batch_size)</span>
<span class="sd">            &gt;&gt;&gt; batch_slices</span>
<span class="sd">            [slice(0, 20, None), slice(20, 40, None), slice(40, 60, None), slice(60, 70, None)]</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batchix</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">obs</span><span class="p">,</span><span class="n">size</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">batchix</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">&lt;</span><span class="n">obs</span> <span class="p">:</span> <span class="n">batchix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="n">batchix</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="n">low</span><span class="p">,</span><span class="n">high</span><span class="p">)</span> <span class="k">for</span> <span class="n">low</span><span class="p">,</span><span class="n">high</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batchix</span><span class="p">,</span><span class="n">batchix</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>
    <span class="k">return</span> <span class="n">batchix</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="neural_net.pipeline.onehot" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">onehot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>One-hot encodes a categorical target variable.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>y</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Numpy array containing the categorical target variable.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: One-hot encoded representation of the target variable.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>      <p>Example:</p>
<pre><code class="language-python">        &gt;&gt;&gt; y = numpy.array([[0],[ 1], [2], [1], [0]])
        &gt;&gt;&gt; onehot_encoded = onehot(y)
        &gt;&gt;&gt; print(onehot_encoded)
        [[1. 0. 0.]
         [0. 1. 0.]
         [0. 0. 1.]
         [0. 1. 0.]
         [1. 0. 0.]]
</code></pre>

          <details class="quote">
            <summary>Source code in <code>neural_net\pipeline.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">onehot</span><span class="p">(</span><span class="n">y</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span> 
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    One-hot encodes a categorical target variable.</span>

<span class="sd">    Args:</span>
<span class="sd">        y (numpy.ndarray): Numpy array containing the categorical target variable.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: One-hot encoded representation of the target variable.</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">            &gt;&gt;&gt; y = numpy.array([[0],[ 1], [2], [1], [0]])</span>
<span class="sd">            &gt;&gt;&gt; onehot_encoded = onehot(y)</span>
<span class="sd">            &gt;&gt;&gt; print(onehot_encoded)</span>
<span class="sd">            [[1. 0. 0.]</span>
<span class="sd">             [0. 1. 0.]</span>
<span class="sd">             [0. 0. 1.]</span>
<span class="sd">             [0. 1. 0.]</span>
<span class="sd">             [1. 0. 0.]]</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="n">numpy</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span><span class="o">+</span><span class="mi">0</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="neural_net.pipeline.scaler" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">scaler</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Custom scaler function for centering and standardizing features.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Input numpy array containing features.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray: Scaled version of the input array.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>      <p>Example:</p>
<pre><code class="language-python">        &gt;&gt;&gt; X = numpy.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
        &gt;&gt;&gt; scaled_X = scaler(X)
        &gt;&gt;&gt; print(scaled_X)
        [[-1.22474487 -1.22474487]
         [ 0.          0.        ]
         [ 1.22474487  1.22474487]]
</code></pre>

          <details class="quote">
            <summary>Source code in <code>neural_net\pipeline.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">scaler</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Custom scaler function for centering and standardizing features.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Input numpy array containing features.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Scaled version of the input array.</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">            &gt;&gt;&gt; X = numpy.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])</span>
<span class="sd">            &gt;&gt;&gt; scaled_X = scaler(X)</span>
<span class="sd">            &gt;&gt;&gt; print(scaled_X)</span>
<span class="sd">            [[-1.22474487 -1.22474487]</span>
<span class="sd">             [ 0.          0.        ]</span>
<span class="sd">             [ 1.22474487  1.22474487]]</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">X</span><span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">/</span><span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="neural_net.pipeline.shuffle" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">shuffle</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>shuffle features and tagert variable numpy arrays X and y using pandas.sample method.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Matrix of training features with shape (n, k), where n is the number of samples
            and k is the number of features.</p>
              </div>
            </li>
            <li>
              <b><code>y</code></b>
                  (<code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>Target variable with shape (n, 1).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code>tuple[<span title="neural_net.utils.numpy.ndarray">ndarray</span>, <span title="neural_net.utils.numpy.ndarray">ndarray</span>]</code>
            –
            <div class="doc-md-description">
              <p>Tuple[numpy.ndarray, numpy.ndarray]: Shuffled X and y arrays.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>      <p>Example:</p>
<pre><code class="language-python">        &gt;&gt;&gt; n,k = 5000,2
        &gt;&gt;&gt; X_train = numpy.random.uniform(-100,100,size=(n,k))
        &gt;&gt;&gt; y_train =( (X_train[:, 0]**2 + X_train[:, 1]**2)/numpy.pi &lt; 1000).reshape(-1,1)+0 
        &gt;&gt;&gt; shuffled_X, shuffled_y = shuffle(X_train, y_train)
        # Now shuffled_X and shuffled_y contain randomly shuffled samples.
</code></pre>

          <details class="quote">
            <summary>Source code in <code>neural_net\pipeline.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">shuffle</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    shuffle features and tagert variable numpy arrays X and y using pandas.sample method.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray): Matrix of training features with shape (n, k), where n is the number of samples</span>
<span class="sd">                        and k is the number of features.</span>
<span class="sd">        y (numpy.ndarray): Target variable with shape (n, 1).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[numpy.ndarray, numpy.ndarray]: Shuffled X and y arrays.</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">            &gt;&gt;&gt; n,k = 5000,2</span>
<span class="sd">            &gt;&gt;&gt; X_train = numpy.random.uniform(-100,100,size=(n,k))</span>
<span class="sd">            &gt;&gt;&gt; y_train =( (X_train[:, 0]**2 + X_train[:, 1]**2)/numpy.pi &lt; 1000).reshape(-1,1)+0 </span>
<span class="sd">            &gt;&gt;&gt; shuffled_X, shuffled_y = shuffle(X_train, y_train)</span>
<span class="sd">            # Now shuffled_X and shuffled_y contain randomly shuffled samples.</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">y</span><span class="o">.</span><span class="n">values</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div><h2 id="9-class-models-used-to-build-other-classes">9. Class Models used to build other classes</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.model"></a>
  <div class="doc doc-contents first">
  
      <p>This modules provides genric templates for other modules</p>
<ul>
<li><code>Define</code> - generic object</li>
<li><code>Architecture</code> - Architecture super object</li>
<li><code>Layer</code> - layer super object<ul>
<li><code>Neurons</code> - neurons super object</li>
<li><code>Cost</code> - cost super object</li>
<li><code>Metrics</code> - weight super object</li>
</ul>
</li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.model.Architecture" class="doc doc-heading">
          <code>Architecture</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Define" href="#neural_net.model.Define">Define</a></code></p>

  
      <p>Model for Architecture functions 
see :func:<code>~architecture.Sequential</code></p>

            <details class="quote">
              <summary>Source code in <code>neural_net\model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Architecture</span><span class="p">(</span><span class="n">Define</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model for Architecture functions </span>
<span class="sd">    see :func:`~architecture.Sequential`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;Architecture&#39;</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.model.Cost" class="doc doc-heading">
          <code>Cost</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Define" href="#neural_net.model.Define">Define</a></code></p>

  
      <p>Model for Cost functions 
see :func:<code>~cost.binaryCrossEntropy</code></p>

            <details class="quote">
              <summary>Source code in <code>neural_net\model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Cost</span><span class="p">(</span><span class="n">Define</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model for Cost functions </span>
<span class="sd">    see :func:`~cost.binaryCrossEntropy`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">clip</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies numpy.clip function described bellow to the predicted probabilities</span>
<span class="sd">        It constrains values between [ε,1-ε] where ε=1e-7</span>

<span class="sd">        clip(a, a_min, a_max, out=None, **kwargs)</span>
<span class="sd">        Clip (limit) the values in an array.</span>

<span class="sd">        Given an interval, values outside the interval are clipped to</span>
<span class="sd">        the interval edges.  For example, if an interval of ``[0, 1]``</span>
<span class="sd">        is specified, values smaller than 0 become 0, and values larger</span>
<span class="sd">        than 1 become 1.</span>

<span class="sd">        Equivalent to but faster than ``np.minimum(a_max, np.maximum(a, a_min))``.</span>

<span class="sd">        No check is performed to ensure ``a_min &lt; a_max``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        a : array_like</span>
<span class="sd">            Array containing elements to clip.</span>
<span class="sd">        a_min, a_max : array_like or None</span>
<span class="sd">            Minimum and maximum value. If ``None``, clipping is not performed on</span>
<span class="sd">            the corresponding edge. Only one of `a_min` and `a_max` may be</span>
<span class="sd">            ``None``. Both are broadcast against `a`.</span>
<span class="sd">        out : ndarray, optional</span>
<span class="sd">            The results will be placed in this array. It may be the input</span>
<span class="sd">            array for in-place clipping.  `out` must be of the right shape</span>
<span class="sd">            to hold the output.  Its type is preserved.</span>
<span class="sd">        **kwargs</span>
<span class="sd">            For other keyword-only arguments, see the</span>
<span class="sd">            :ref:`ufunc docs &lt;ufuncs.kwargs&gt;`.</span>

<span class="sd">            .. versionadded:: 1.17.0</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        clipped_array : ndarray</span>
<span class="sd">            An array with the elements of `a`, but where values</span>
<span class="sd">            &lt; `a_min` are replaced with `a_min`, and those &gt; `a_max`</span>
<span class="sd">            with `a_max`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        :ref:`ufuncs-output-type`</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        When `a_min` is greater than `a_max`, `clip` returns an</span>
<span class="sd">        array in which all values are equal to `a_max`,</span>
<span class="sd">        as shown in the second example.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        ```python</span>
<span class="sd">                &gt;&gt;&gt; a = np.arange(10)</span>
<span class="sd">                &gt;&gt;&gt; a</span>
<span class="sd">                array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
<span class="sd">                &gt;&gt;&gt; np.clip(a, 1, 8)</span>
<span class="sd">                array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])</span>
<span class="sd">                &gt;&gt;&gt; np.clip(a, 8, 1)</span>
<span class="sd">                array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])</span>
<span class="sd">                &gt;&gt;&gt; np.clip(a, 3, 6, out=a)</span>
<span class="sd">                array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])</span>
<span class="sd">                &gt;&gt;&gt; a</span>
<span class="sd">                array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])</span>
<span class="sd">                &gt;&gt;&gt; a = np.arange(10)</span>
<span class="sd">                &gt;&gt;&gt; a</span>
<span class="sd">                array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
<span class="sd">                &gt;&gt;&gt; np.clip(a, [3, 4, 1, 1, 1, 4, 4, 4, 4, 4], 8)</span>
<span class="sd">                array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ε</span> <span class="o">=</span> <span class="mf">1e-7</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">ε</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">ε</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;Cost&#39;</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Cost.clip" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">clip</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Applies numpy.clip function described bellow to the predicted probabilities
It constrains values between [ε,1-ε] where ε=1e-7</p>
<p>clip(a, a_min, a_max, out=None, **kwargs)
Clip (limit) the values in an array.</p>
<p>Given an interval, values outside the interval are clipped to
the interval edges.  For example, if an interval of <code>[0, 1]</code>
is specified, values smaller than 0 become 0, and values larger
than 1 become 1.</p>
<p>Equivalent to but faster than <code>np.minimum(a_max, np.maximum(a, a_min))</code>.</p>
<p>No check is performed to ensure <code>a_min &lt; a_max</code>.</p>
<h5 id="neural_net.model.Cost.clip--parameters">Parameters</h5>
<p>a : array_like
    Array containing elements to clip.
a_min, a_max : array_like or None
    Minimum and maximum value. If <code>None</code>, clipping is not performed on
    the corresponding edge. Only one of <code>a_min</code> and <code>a_max</code> may be
    <code>None</code>. Both are broadcast against <code>a</code>.
out : ndarray, optional
    The results will be placed in this array. It may be the input
    array for in-place clipping.  <code>out</code> must be of the right shape
    to hold the output.  Its type is preserved.
**kwargs
    For other keyword-only arguments, see the
    :ref:<code>ufunc docs &lt;ufuncs.kwargs&gt;</code>.</p>
<pre><code>.. versionadded:: 1.17.0
</code></pre>
<h5 id="neural_net.model.Cost.clip--returns">Returns</h5>
<p>clipped_array : ndarray
    An array with the elements of <code>a</code>, but where values
    &lt; <code>a_min</code> are replaced with <code>a_min</code>, and those &gt; <code>a_max</code>
    with <code>a_max</code>.</p>
<h5 id="neural_net.model.Cost.clip--see-also">See Also</h5>
<p>:ref:<code>ufuncs-output-type</code></p>
<h5 id="neural_net.model.Cost.clip--notes">Notes</h5>
<p>When <code>a_min</code> is greater than <code>a_max</code>, <code>clip</code> returns an
array in which all values are equal to <code>a_max</code>,
as shown in the second example.</p>
<h5 id="neural_net.model.Cost.clip--examples">Examples</h5>
<pre><code class="language-python">        &gt;&gt;&gt; a = np.arange(10)
        &gt;&gt;&gt; a
        array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
        &gt;&gt;&gt; np.clip(a, 1, 8)
        array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])
        &gt;&gt;&gt; np.clip(a, 8, 1)
        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
        &gt;&gt;&gt; np.clip(a, 3, 6, out=a)
        array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])
        &gt;&gt;&gt; a
        array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])
        &gt;&gt;&gt; a = np.arange(10)
        &gt;&gt;&gt; a
        array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
        &gt;&gt;&gt; np.clip(a, [3, 4, 1, 1, 1, 4, 4, 4, 4, 4], 8)
        array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])
</code></pre>

          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">clip</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies numpy.clip function described bellow to the predicted probabilities</span>
<span class="sd">    It constrains values between [ε,1-ε] where ε=1e-7</span>

<span class="sd">    clip(a, a_min, a_max, out=None, **kwargs)</span>
<span class="sd">    Clip (limit) the values in an array.</span>

<span class="sd">    Given an interval, values outside the interval are clipped to</span>
<span class="sd">    the interval edges.  For example, if an interval of ``[0, 1]``</span>
<span class="sd">    is specified, values smaller than 0 become 0, and values larger</span>
<span class="sd">    than 1 become 1.</span>

<span class="sd">    Equivalent to but faster than ``np.minimum(a_max, np.maximum(a, a_min))``.</span>

<span class="sd">    No check is performed to ensure ``a_min &lt; a_max``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array containing elements to clip.</span>
<span class="sd">    a_min, a_max : array_like or None</span>
<span class="sd">        Minimum and maximum value. If ``None``, clipping is not performed on</span>
<span class="sd">        the corresponding edge. Only one of `a_min` and `a_max` may be</span>
<span class="sd">        ``None``. Both are broadcast against `a`.</span>
<span class="sd">    out : ndarray, optional</span>
<span class="sd">        The results will be placed in this array. It may be the input</span>
<span class="sd">        array for in-place clipping.  `out` must be of the right shape</span>
<span class="sd">        to hold the output.  Its type is preserved.</span>
<span class="sd">    **kwargs</span>
<span class="sd">        For other keyword-only arguments, see the</span>
<span class="sd">        :ref:`ufunc docs &lt;ufuncs.kwargs&gt;`.</span>

<span class="sd">        .. versionadded:: 1.17.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    clipped_array : ndarray</span>
<span class="sd">        An array with the elements of `a`, but where values</span>
<span class="sd">        &lt; `a_min` are replaced with `a_min`, and those &gt; `a_max`</span>
<span class="sd">        with `a_max`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    :ref:`ufuncs-output-type`</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    When `a_min` is greater than `a_max`, `clip` returns an</span>
<span class="sd">    array in which all values are equal to `a_max`,</span>
<span class="sd">    as shown in the second example.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    ```python</span>
<span class="sd">            &gt;&gt;&gt; a = np.arange(10)</span>
<span class="sd">            &gt;&gt;&gt; a</span>
<span class="sd">            array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
<span class="sd">            &gt;&gt;&gt; np.clip(a, 1, 8)</span>
<span class="sd">            array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])</span>
<span class="sd">            &gt;&gt;&gt; np.clip(a, 8, 1)</span>
<span class="sd">            array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])</span>
<span class="sd">            &gt;&gt;&gt; np.clip(a, 3, 6, out=a)</span>
<span class="sd">            array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])</span>
<span class="sd">            &gt;&gt;&gt; a</span>
<span class="sd">            array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])</span>
<span class="sd">            &gt;&gt;&gt; a = np.arange(10)</span>
<span class="sd">            &gt;&gt;&gt; a</span>
<span class="sd">            array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
<span class="sd">            &gt;&gt;&gt; np.clip(a, [3, 4, 1, 1, 1, 4, 4, 4, 4, 4], 8)</span>
<span class="sd">            array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ε</span> <span class="o">=</span> <span class="mf">1e-7</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">ε</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">ε</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.model.Define" class="doc doc-heading">
          <code>Define</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.db.DBmanager" href="#neural_net.db.DBmanager">DBmanager</a></code></p>


            <details class="quote">
              <summary>Source code in <code>neural_net\model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Define</span><span class="p">(</span><span class="n">DBmanager</span><span class="p">):</span>

    <span class="n">__store</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the name of the class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: The name of the class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_id</span> 

    <span class="nd">@id</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">loc</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets id property for the class</span>
<span class="sd">        Instantiate and stores sqlalchemy table of self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">unfold</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_id</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s1">_id&#39;</span><span class="p">:</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span><span class="s1">&#39;name&#39;</span><span class="p">:</span><span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span><span class="o">**</span><span class="n">loc</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;table&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">table</span> <span class="o">=</span> <span class="n">get_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_table</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">table</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">update_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">ix</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">any</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span>
    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">ix</span><span class="p">,</span><span class="n">val</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="o">.</span><span class="n">get</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">get</span>


    <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">loc</span><span class="p">:</span><span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Triggers the id property</span>

<span class="sd">        Args:</span>
<span class="sd">            loc (dict) : dictionary of properties</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">loc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">class</span> <span class="nc">func</span><span class="p">:</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">_</span><span class="p">):</span><span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;Layer_init_method&#39;</span><span class="p">,</span><span class="n">func</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;func&#39;</span><span class="p">,</span><span class="n">func</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;steps&#39;</span><span class="p">,[])</span>
        <span class="n">parent</span> <span class="o">=</span><span class="p">{</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s1">_id&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]}</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="bp">self</span> <span class="p">:</span> 
            <span class="n">step</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">step</span><span class="o">.</span><span class="n">id</span><span class="p">,</span><span class="o">**</span><span class="n">parent</span><span class="p">}</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">object</span><span class="p">:</span> <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">])</span>


    <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">any</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="o">&lt;</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">raise</span> <span class="ne">StopIteration</span>   
    <span class="k">def</span> <span class="nf">commit</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span><span class="p">:</span>
            <span class="n">DBmanager</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implements forward prediction of input feature matrix X of size n,k</span>
<span class="sd">        Passes outputs from input layer to output layer</span>

<span class="sd">        Args:</span>
<span class="sd">            X (numpy.ndarray) : input features matrix</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray of output layer predictions</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">X</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">step</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Δ</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span> <span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement backpropagation of cost gradient to all layers</span>
<span class="sd">        Passes gradients backward</span>

<span class="sd">        Args:</span>
<span class="sd">            Δ (numpy.ndarray) : array of gradient from next step</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy array of input layer gradient</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">Δ</span> <span class="o">=</span> <span class="n">step</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">Δ</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Δ</span>

    <span class="k">def</span> <span class="nf">compute_store</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generic method that computes item and stores it to sqlalchemy session</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
            <span class="k">del</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">table</span><span class="p">)</span>
        <span class="bp">self</span> <span class="o">+</span> <span class="p">{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span><span class="o">**</span><span class="nb">locals</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">value</span>

    <span class="k">def</span> <span class="nf">updateW</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Updates sqlalchemy tables containing weights</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">Neurons</span><span class="o">.</span><span class="n">with_weights</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">Wtables</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">table</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">r</span><span class="p">):</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">table</span><span class="p">,</span><span class="s1">&#39;value&#39;</span><span class="p">,</span><span class="n">obj</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Define.__add__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__add__</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Triggers the id property</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>loc</code></b>
                  (<code>dict) </code>)
              –
              <div class="doc-md-description">
                <p>dictionary of properties</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">loc</span><span class="p">:</span><span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Triggers the id property</span>

<span class="sd">    Args:</span>
<span class="sd">        loc (dict) : dictionary of properties</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">loc</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">class</span> <span class="nc">func</span><span class="p">:</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">_</span><span class="p">):</span><span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">init_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;Layer_init_method&#39;</span><span class="p">,</span><span class="n">func</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;func&#39;</span><span class="p">,</span><span class="n">func</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;steps&#39;</span><span class="p">,[])</span>
    <span class="n">parent</span> <span class="o">=</span><span class="p">{</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s1">_id&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]}</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="bp">self</span> <span class="p">:</span> 
        <span class="n">step</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">step</span><span class="o">.</span><span class="n">id</span><span class="p">,</span><span class="o">**</span><span class="n">parent</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Define.__repr__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__repr__</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Returns the name of the class.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>str</code></b>(                <code>str</code>
)            –
            <div class="doc-md-description">
              <p>The name of the class.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the name of the class.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: The name of the class.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Define.compute_store" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute_store</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Generic method that computes item and stores it to sqlalchemy session</p>

          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_store</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generic method that computes item and stores it to sqlalchemy session</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
        <span class="k">del</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">table</span><span class="p">)</span>
    <span class="bp">self</span> <span class="o">+</span> <span class="p">{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="p">,</span><span class="o">**</span><span class="nb">locals</span><span class="p">()}</span>
    <span class="k">return</span> <span class="n">value</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Define.predict" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Implements forward prediction of input feature matrix X of size n,k
Passes outputs from input layer to output layer</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code>numpy.ndarray) </code>)
              –
              <div class="doc-md-description">
                <p>input features matrix</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray of output layer predictions</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements forward prediction of input feature matrix X of size n,k</span>
<span class="sd">    Passes outputs from input layer to output layer</span>

<span class="sd">    Args:</span>
<span class="sd">        X (numpy.ndarray) : input features matrix</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray of output layer predictions</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">X</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">step</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Define.update" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">update</span><span class="p">(</span><span class="n">Δ</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Implement backpropagation of cost gradient to all layers
Passes gradients backward</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>Δ</code></b>
                  (<code>numpy.ndarray) </code>)
              –
              <div class="doc-md-description">
                <p>array of gradient from next step</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy array of input layer gradient</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Δ</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span> <span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implement backpropagation of cost gradient to all layers</span>
<span class="sd">    Passes gradients backward</span>

<span class="sd">    Args:</span>
<span class="sd">        Δ (numpy.ndarray) : array of gradient from next step</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy array of input layer gradient</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">Δ</span> <span class="o">=</span> <span class="n">step</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">Δ</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Δ</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Define.updateW" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">updateW</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Updates sqlalchemy tables containing weights</p>

          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">updateW</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates sqlalchemy tables containing weights</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">Neurons</span><span class="o">.</span><span class="n">with_weights</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">Wtables</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">table</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">r</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">table</span><span class="p">,</span><span class="s1">&#39;value&#39;</span><span class="p">,</span><span class="n">obj</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.model.Layer" class="doc doc-heading">
          <code>Layer</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Define" href="#neural_net.model.Define">Define</a></code></p>

  
      <p>Model for layer functions 
see :func:<code>~layer.fullyconnected</code></p>

            <details class="quote">
              <summary>Source code in <code>neural_net\model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="n">Define</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model for layer functions </span>
<span class="sd">    see :func:`~layer.fullyconnected`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;Layer&#39;</span>  
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.model.Metrics" class="doc doc-heading">
          <code>Metrics</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Define" href="#neural_net.model.Define">Define</a></code></p>

  
      <p>Model for Metrics functions 
see :func:<code>~metrics.accuracy</code></p>

            <details class="quote">
              <summary>Source code in <code>neural_net\model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Metrics</span><span class="p">(</span><span class="n">Define</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model for Metrics functions </span>
<span class="sd">    see :func:`~metrics.accuracy`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;Metrics&#39;</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.model.Neurons" class="doc doc-heading">
          <code>Neurons</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="neural_net.model.Define" href="#neural_net.model.Define">Define</a></code></p>

  
      <p>Model for activation functions 
see :func:<code>~activation.Softmax</code></p>

            <details class="quote">
              <summary>Source code in <code>neural_net\model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Neurons</span><span class="p">(</span><span class="n">Define</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model for activation functions </span>
<span class="sd">    see :func:`~activation.Softmax`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">with_weights</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">instantiateW</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate weight tables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span><span class="p">:</span>
            <span class="n">table</span><span class="p">,</span><span class="n">cols</span> <span class="o">=</span> <span class="n">tables</span><span class="p">[</span><span class="s1">&#39;Weight&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wtables</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">):</span>
                <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">r</span><span class="p">):</span>
                    <span class="n">instances</span> <span class="o">+=</span> <span class="p">[</span>

                        <span class="n">table</span><span class="p">(</span><span class="n">Weight_id</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                            <span class="n">value</span><span class="o">=</span><span class="n">e</span><span class="p">,</span>
                            <span class="n">Neurons_id</span><span class="o">=</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
                            <span class="p">)</span>
                    <span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Wtables</span> <span class="o">+=</span> <span class="p">[</span><span class="n">instances</span><span class="p">]</span>
                <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">Neurons</span><span class="o">.</span><span class="n">with_weights</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="p">]</span>


    <span class="k">def</span> <span class="nf">storeW</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Stores weights tables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wtables</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="n">row</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">add_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;Neurons&#39;</span>

    <span class="k">def</span> <span class="fm">__sub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Δ</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Substracts Gradient to Weights</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">-=</span> <span class="n">Δ</span>

    <span class="k">def</span> <span class="nf">n</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span> 
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns sample size for current features matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>


    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Δ</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes gradient for previous step</span>

<span class="sd">        Args:</span>
<span class="sd">            Δ (numpy.ndarray) : gradient from next step</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray of gradient for previous step</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Δ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pr</span><span class="p">()</span><span class="o">*</span><span class="n">Δ</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Δ</span>  
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Neurons.__sub__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__sub__</span><span class="p">(</span><span class="n">Δ</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Substracts Gradient to Weights</p>

          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__sub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Δ</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Substracts Gradient to Weights</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">-=</span> <span class="n">Δ</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Neurons.grad" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">grad</span><span class="p">(</span><span class="n">Δ</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes gradient for previous step</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>Δ</code></b>
                  (<code>numpy.ndarray) </code>)
              –
              <div class="doc-md-description">
                <p>gradient from next step</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
                <code><span title="neural_net.utils.numpy.ndarray">ndarray</span></code>
            –
            <div class="doc-md-description">
              <p>numpy.ndarray of gradient for previous step</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">Δ</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes gradient for previous step</span>

<span class="sd">    Args:</span>
<span class="sd">        Δ (numpy.ndarray) : gradient from next step</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray of gradient for previous step</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Δ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pr</span><span class="p">()</span><span class="o">*</span><span class="n">Δ</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Δ</span>  
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Neurons.instantiateW" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">instantiateW</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Instantiate weight tables</p>

          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">instantiateW</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Instantiate weight tables</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span><span class="p">:</span>
        <span class="n">table</span><span class="p">,</span><span class="n">cols</span> <span class="o">=</span> <span class="n">tables</span><span class="p">[</span><span class="s1">&#39;Weight&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Wtables</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">):</span>
            <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">r</span><span class="p">):</span>
                <span class="n">instances</span> <span class="o">+=</span> <span class="p">[</span>

                    <span class="n">table</span><span class="p">(</span><span class="n">Weight_id</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                        <span class="n">value</span><span class="o">=</span><span class="n">e</span><span class="p">,</span>
                        <span class="n">Neurons_id</span><span class="o">=</span><span class="bp">self</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
                        <span class="p">)</span>
                <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wtables</span> <span class="o">+=</span> <span class="p">[</span><span class="n">instances</span><span class="p">]</span>
            <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">Neurons</span><span class="o">.</span><span class="n">with_weights</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Neurons.n" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">n</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Returns sample size for current features matrix</p>

          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">n</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span> 
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns sample size for current features matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="neural_net.model.Neurons.storeW" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">storeW</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Stores weights tables</p>

          <details class="quote">
            <summary>Source code in <code>neural_net\model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">storeW</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Stores weights tables</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">Define</span><span class="o">.</span><span class="n">_Define__store</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wtables</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="n">row</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div><h2 id="10-utility-functions">10. Utility functions</h2>


<div class="doc doc-object doc-module">



<a id="neural_net.utils"></a>
  <div class="doc doc-contents first">
  
      <p>Provides utility functions</p>
<ul>
<li><code>get_module_path</code> - Returns the path to a subdirectory named 'dir' relative to the currently executed script.</li>
<li><code>now</code> - current timestamp</li>
<li><code>unfold</code> - Unfolds a nested dictionary by appending the values of inner dictionaries to the outer dictionary.</li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="neural_net.utils.HouseDatasetDownloader" class="doc doc-heading">
          <code>HouseDatasetDownloader</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Downloads boston housing dataset.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>src</code></b>
              –
              <div class="doc-md-description">
                <p>str
URL to the online CSV file containing the Iris dataset default at https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>columns</code></b>
              –
              <div class="doc-md-description">
                <p>list of str
ordered list of columns in the dataset.</p>
              </div>
            </li>
            <li>
              <b><code>data</code></b>
              –
              <div class="doc-md-description">
                <p>array
data array of features and target variable</p>
              </div>
            </li>
            <li>
              <b><code>csv</code></b>
              –
              <div class="doc-md-description">
                <p>str
Raw CSV textfile</p>
              </div>
            </li>
            <li>
              <b><code>description</code></b>
              –
              <div class="doc-md-description">
                <p>str
Full description of housing database</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
<details class="example" open>
  <summary>Example</summary>
  <pre><code class="language-python">    &gt;&gt;&gt; houseloader = HouseDatasetDownloader()
    &gt;&gt;&gt; houseloader.load_dataset()
    &gt;&gt;&gt; print(houseloader.columns)
    ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']
    &gt;&gt;&gt; print(houseloader.data)
    [[6.3200e-03 1.8000e+01 2.3100e+00 ... 3.9690e+02 4.9800e+00 2.4000e+01]
    [2.7310e-02 0.0000e+00 7.0700e+00 ... 3.9690e+02 9.1400e+00 2.1600e+01]
    [2.7290e-02 0.0000e+00 7.0700e+00 ... 3.9283e+02 4.0300e+00 3.4700e+01]
    ...
    [6.0760e-02 0.0000e+00 1.1930e+01 ... 3.9690e+02 5.6400e+00 2.3900e+01]
    [1.0959e-01 0.0000e+00 1.1930e+01 ... 3.9345e+02 6.4800e+00 2.2000e+01]
    [4.7410e-02 0.0000e+00 1.1930e+01 ... 3.9690e+02 7.8800e+00 1.1900e+01]]
</code></pre>
</details>
            <details class="quote">
              <summary>Source code in <code>neural_net\utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">HouseDatasetDownloader</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Downloads boston housing dataset.</span>


<span class="sd">        Parameters:</span>
<span class="sd">            src : str</span>
<span class="sd">                URL to the online CSV file containing the Iris dataset default at https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv</span>

<span class="sd">        Attributes:</span>
<span class="sd">            columns : list of str</span>
<span class="sd">                ordered list of columns in the dataset.</span>
<span class="sd">            data : array</span>
<span class="sd">                data array of features and target variable</span>
<span class="sd">            csv : str</span>
<span class="sd">                Raw CSV textfile</span>
<span class="sd">            description : str</span>
<span class="sd">                Full description of housing database</span>

<span class="sd">        Example:</span>
<span class="sd">            ```python</span>
<span class="sd">                &gt;&gt;&gt; houseloader = HouseDatasetDownloader()</span>
<span class="sd">                &gt;&gt;&gt; houseloader.load_dataset()</span>
<span class="sd">                &gt;&gt;&gt; print(houseloader.columns)</span>
<span class="sd">                [&#39;CRIM&#39;, &#39;ZN&#39;, &#39;INDUS&#39;, &#39;CHAS&#39;, &#39;NOX&#39;, &#39;RM&#39;, &#39;AGE&#39;, &#39;DIS&#39;, &#39;RAD&#39;, &#39;TAX&#39;, &#39;PTRATIO&#39;, &#39;B&#39;, &#39;LSTAT&#39;, &#39;MEDV&#39;]</span>
<span class="sd">                &gt;&gt;&gt; print(houseloader.data)</span>
<span class="sd">                [[6.3200e-03 1.8000e+01 2.3100e+00 ... 3.9690e+02 4.9800e+00 2.4000e+01]</span>
<span class="sd">                [2.7310e-02 0.0000e+00 7.0700e+00 ... 3.9690e+02 9.1400e+00 2.1600e+01]</span>
<span class="sd">                [2.7290e-02 0.0000e+00 7.0700e+00 ... 3.9283e+02 4.0300e+00 3.4700e+01]</span>
<span class="sd">                ...</span>
<span class="sd">                [6.0760e-02 0.0000e+00 1.1930e+01 ... 3.9690e+02 5.6400e+00 2.3900e+01]</span>
<span class="sd">                [1.0959e-01 0.0000e+00 1.1930e+01 ... 3.9345e+02 6.4800e+00 2.2000e+01]</span>
<span class="sd">                [4.7410e-02 0.0000e+00 1.1930e+01 ... 3.9690e+02 7.8800e+00 1.1900e+01]]</span>
<span class="sd">            ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;http://lib.stat.cmu.edu/datasets/boston&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src</span> <span class="o">=</span> <span class="n">src</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">csv</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load the House dataset from the specified online CSV source.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">csv</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">description</span><span class="p">,</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;0.00632&quot;</span><span class="p">)],</span><span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;0.00632&quot;</span><span class="p">):]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">  &#39;</span><span class="p">,</span><span class="s1">&#39;  &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(\d+\.*\d*)&#39;</span><span class="p">,</span><span class="n">r</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">16</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]]</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.utils.HouseDatasetDownloader.load_dataset" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">load_dataset</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Load the House dataset from the specified online CSV source.</p>

          <details class="quote">
            <summary>Source code in <code>neural_net\utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load the House dataset from the specified online CSV source.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">description</span><span class="p">,</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;0.00632&quot;</span><span class="p">)],</span><span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;0.00632&quot;</span><span class="p">):]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">  &#39;</span><span class="p">,</span><span class="s1">&#39;  &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(\d+\.*\d*)&#39;</span><span class="p">,</span><span class="n">r</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">16</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]]</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.utils.IrisDatasetDownloader" class="doc doc-heading">
          <code>IrisDatasetDownloader</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Downloads the Iris dataset from an online CSV source.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>src</code></b>
              –
              <div class="doc-md-description">
                <p>str
URL to the online CSV file containing the Iris dataset default at https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>target_names</code></b>
              –
              <div class="doc-md-description">
                <p>list of str
Names of each target label (species) in the dataset.</p>
              </div>
            </li>
            <li>
              <b><code>feature_names</code></b>
              –
              <div class="doc-md-description">
                <p>list of str
Names of all features (attributes) in the dataset.</p>
              </div>
            </li>
            <li>
              <b><code>csv</code></b>
              –
              <div class="doc-md-description">
                <p>str
raw CSV textfile</p>
              </div>
            </li>
            <li>
              <b><code>description</code></b>
              –
              <div class="doc-md-description">
                <p>str
Full description of iris database</p>
              </div>
            </li>
            <li>
              <b><code>data</code></b>
              –
              <div class="doc-md-description">
                <p>numpy.ndarray
array of all features</p>
              </div>
            </li>
            <li>
              <b><code>target</code></b>
              –
              <div class="doc-md-description">
                <p>numpy.ndarray
array of target variable</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
<details class="example" open>
  <summary>Example</summary>
  <pre><code class="language-python">    &gt;&gt;&gt; iris = IrisDatasetDownloader()
    &gt;&gt;&gt; iris.load_dataset()
    &gt;&gt;&gt; print(iris.data.shape,iris.target.shape)
    (150, 4) (150, 1)
    &gt;&gt;&gt; print(iris.target_names)
    ['setosa', 'versicolor', 'virginica']
    &gt;&gt;&gt; print(iris.feature_names)
    ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
    &gt;&gt;&gt; print(iris.data[:5,:])
    [[5.1 3.5 1.4 0.2]
    [4.9 3.  1.4 0.2]
    [4.7 3.2 1.3 0.2]
    [4.6 3.1 1.5 0.2]
    [5.  3.6 1.4 0.2]]
    &gt;&gt;&gt; print(iris.target[:5,:])
    [[0]
     [0]
     [0]
     [0]
     [0]]
</code></pre>
</details>
            <details class="quote">
              <summary>Source code in <code>neural_net\utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">IrisDatasetDownloader</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Downloads the Iris dataset from an online CSV source.</span>


<span class="sd">        Parameters:</span>
<span class="sd">            src : str</span>
<span class="sd">                URL to the online CSV file containing the Iris dataset default at https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv</span>

<span class="sd">        Attributes:</span>
<span class="sd">            target_names : list of str</span>
<span class="sd">                Names of each target label (species) in the dataset.</span>
<span class="sd">            feature_names : list of str</span>
<span class="sd">                Names of all features (attributes) in the dataset.</span>
<span class="sd">            csv : str</span>
<span class="sd">                raw CSV textfile</span>
<span class="sd">            description : str</span>
<span class="sd">                Full description of iris database</span>
<span class="sd">            data : numpy.ndarray</span>
<span class="sd">                array of all features</span>
<span class="sd">            target : numpy.ndarray</span>
<span class="sd">                array of target variable</span>

<span class="sd">        Example:</span>
<span class="sd">            ```python</span>
<span class="sd">                &gt;&gt;&gt; iris = IrisDatasetDownloader()</span>
<span class="sd">                &gt;&gt;&gt; iris.load_dataset()</span>
<span class="sd">                &gt;&gt;&gt; print(iris.data.shape,iris.target.shape)</span>
<span class="sd">                (150, 4) (150, 1)</span>
<span class="sd">                &gt;&gt;&gt; print(iris.target_names)</span>
<span class="sd">                [&#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39;]</span>
<span class="sd">                &gt;&gt;&gt; print(iris.feature_names)</span>
<span class="sd">                [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;]</span>
<span class="sd">                &gt;&gt;&gt; print(iris.data[:5,:])</span>
<span class="sd">                [[5.1 3.5 1.4 0.2]</span>
<span class="sd">                [4.9 3.  1.4 0.2]</span>
<span class="sd">                [4.7 3.2 1.3 0.2]</span>
<span class="sd">                [4.6 3.1 1.5 0.2]</span>
<span class="sd">                [5.  3.6 1.4 0.2]]</span>
<span class="sd">                &gt;&gt;&gt; print(iris.target[:5,:])</span>
<span class="sd">                [[0]</span>
<span class="sd">                 [0]</span>
<span class="sd">                 [0]</span>
<span class="sd">                 [0]</span>
<span class="sd">                 [0]]</span>
<span class="sd">            ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">description</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        1. Title: Iris Plants Database</span>
<span class="s2">            Updated Sept 21 by C.Blake - Added discrepency information</span>

<span class="s2">        2. Sources:</span>
<span class="s2">            (a) Creator: R.A. Fisher</span>
<span class="s2">            (b) Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)</span>
<span class="s2">            (c) Date: July, 1988</span>

<span class="s2">        3. Past Usage:</span>
<span class="s2">            - Publications: too many to mention!!!  Here are a few.</span>
<span class="s2">        1. Fisher,R.A. &quot;The use of multiple measurements in taxonomic problems&quot;</span>
<span class="s2">            Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions</span>
<span class="s2">            to Mathematical Statistics&quot; (John Wiley, NY, 1950).</span>
<span class="s2">        2. Duda,R.O., &amp; Hart,P.E. (1973) Pattern Classification and Scene Analysis.</span>
<span class="s2">            (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.</span>
<span class="s2">        3. Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System</span>
<span class="s2">            Structure and Classification Rule for Recognition in Partially Exposed</span>
<span class="s2">            Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine</span>
<span class="s2">            Intelligence, Vol. PAMI-2, No. 1, 67-71.</span>
<span class="s2">            -- Results:</span>
<span class="s2">                -- very low misclassification rates (0</span><span class="si">% f</span><span class="s2">or the setosa class)</span>
<span class="s2">        4. Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE </span>
<span class="s2">            Transactions on Information Theory, May 1972, 431-433.</span>
<span class="s2">            -- Results:</span>
<span class="s2">                -- very low misclassification rates again</span>
<span class="s2">        5. See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&#39;s AUTOCLASS II</span>
<span class="s2">            conceptual clustering system finds 3 classes in the data.</span>

<span class="s2">        4. Relevant Information:</span>
<span class="s2">            --- This is perhaps the best known database to be found in the pattern</span>
<span class="s2">                recognition literature.  Fisher&#39;s paper is a classic in the field</span>
<span class="s2">                and is referenced frequently to this day.  (See Duda &amp; Hart, for</span>
<span class="s2">                example.)  The data set contains 3 classes of 50 instances each,</span>
<span class="s2">                where each class refers to a type of iris plant.  One class is</span>
<span class="s2">                linearly separable from the other 2; the latter are NOT linearly</span>
<span class="s2">                separable from each other.</span>
<span class="s2">            --- Predicted attribute: class of iris plant.</span>
<span class="s2">            --- This is an exceedingly simple domain.</span>
<span class="s2">            --- This data differs from the data presented in Fishers article</span>
<span class="s2">                (identified by Steve Chadwick,  spchadwick@espeedaz.net )</span>
<span class="s2">                The 35th sample should be: 4.9,3.1,1.5,0.2,&quot;Iris-setosa&quot;</span>
<span class="s2">                where the error is in the fourth feature.</span>
<span class="s2">                The 38th sample: 4.9,3.6,1.4,0.1,&quot;Iris-setosa&quot;</span>
<span class="s2">                where the errors are in the second and third features.  </span>

<span class="s2">        5. Number of Instances: 150 (50 in each of three classes)</span>

<span class="s2">        6. Number of Attributes: 4 numeric, predictive attributes and the class</span>

<span class="s2">        7. Attribute Information:</span>
<span class="s2">            1. sepal length in cm</span>
<span class="s2">            2. sepal width in cm</span>
<span class="s2">            3. petal length in cm</span>
<span class="s2">            4. petal width in cm</span>
<span class="s2">            5. class: </span>
<span class="s2">                -- Iris Setosa</span>
<span class="s2">                -- Iris Versicolour</span>
<span class="s2">                -- Iris Virginica</span>

<span class="s2">        8. Missing Attribute Values: None</span>

<span class="s2">        Summary Statistics:</span>
<span class="s2">                    Min  Max   Mean    SD   Class Correlation</span>
<span class="s2">           sepal length: 4.3  7.9   5.84  0.83    0.7826   </span>
<span class="s2">            sepal width: 2.0  4.4   3.05  0.43   -0.4194</span>
<span class="s2">           petal length: 1.0  6.9   3.76  1.76    0.9490  (high!)</span>
<span class="s2">            petal width: 0.1  2.5   1.20  0.76    0.9565  (high!)</span>

<span class="s2">        9. Class Distribution: 33.3</span><span class="si">% f</span><span class="s2">or each of 3 classes.</span>
<span class="s2">        &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src</span> <span class="o">=</span> <span class="n">src</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_width&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">csv</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load the Iris dataset from the specified online CSV source.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">csv</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
        <span class="n">columns</span><span class="p">,</span><span class="o">*</span><span class="n">data</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">data</span><span class="p">,</span><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">data</span><span class="p">],[</span><span class="n">r</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">data</span> <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">target</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">l</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span> <span class="o">+=</span> <span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">target</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">=</span> <span class="n">columns</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span><span class="s1">&#39; (cm)&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.utils.IrisDatasetDownloader.load_dataset" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">load_dataset</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Load the Iris dataset from the specified online CSV source.</p>

          <details class="quote">
            <summary>Source code in <code>neural_net\utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load the Iris dataset from the specified online CSV source.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="n">columns</span><span class="p">,</span><span class="o">*</span><span class="n">data</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">csv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">data</span><span class="p">,</span><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">data</span><span class="p">],[</span><span class="n">r</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">data</span> <span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">target</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">l</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_names</span> <span class="o">+=</span> <span class="p">[</span><span class="n">l</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">target</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">=</span> <span class="n">columns</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span><span class="s1">&#39; (cm)&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h2 id="neural_net.utils.Pearson" class="doc doc-heading">
          <code>Pearson</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Computes the Pearson correlation matrix and generates a heatmap.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Attributes:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
              –
              <div class="doc-md-description">
                <p>numpy.ndarray
The input data containing features.</p>
              </div>
            </li>
            <li>
              <b><code>n</code></b>
              –
              <div class="doc-md-description">
                <p>int
number of observations</p>
              </div>
            </li>
            <li>
              <b><code>k</code></b>
              –
              <div class="doc-md-description">
                <p>int
number of features</p>
              </div>
            </li>
            <li>
              <b><code>cols</code></b>
              –
              <div class="doc-md-description">
                <p>list
list of fed columns</p>
              </div>
            </li>
            <li>
              <b><code>cov</code></b>
              –
              <div class="doc-md-description">
                <p>numpy.ndarray
covariance matrix</p>
              </div>
            </li>
            <li>
              <b><code>var</code></b>
              –
              <div class="doc-md-description">
                <p>numpy.ndarray
variance matrix</p>
              </div>
            </li>
            <li>
              <b><code>corr</code></b>
                  (<code><span title="numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>numpy.ndarray
correlation matrix</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


  <p><strong>Methods:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
          <tr>
            <td><code><a class="autorefs autorefs-internal" title="neural_net.utils.Pearson.__init__" href="#neural_net.utils.Pearson.__init__">__init__</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>numpy.ndarray,cols:list=None)-&gt;None:
Initialize Pearson object</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><span title="neural_net.utils.Pearson.corr">corr</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>computes Pearson correlation matrix</p>
              </div>
            </td>
          </tr>
          <tr>
            <td><code><span title="neural_net.utils.Pearson.heatmap">heatmap</span></code></td>
            <td>
              <div class="doc-md-description">
                <p>int=6,digits:int=1, xrotation:Union[int,str]=45,yrotation:Union[int,str]='horizontal') -&gt; None:
plots correlation heatmap</p>
              </div>
            </td>
          </tr>
    </tbody>
  </table>

<details class="example" open>
  <summary>Example</summary>
  <pre><code class="language-python">    &gt;&gt;&gt; import pandas as pd
    &gt;&gt;&gt; from matplotlib import pyplot as plt
    &gt;&gt;&gt;
    &gt;&gt;&gt; # Create a sample dataset
    &gt;&gt;&gt; data = pd.DataFrame({
    ...     'feature1': [1, 2, 3, 4, 5],
    ...     'feature2': [5, 4, 3, 2, 1],
    ...     'feature3': [3, 3, 3, 3, 3]
    ... })
    &gt;&gt;&gt;
    &gt;&gt;&gt; # Initialize the Pearson correlation analyzer
    &gt;&gt;&gt; pearson_analyzer = Pearson(X=data.values,cols=data.columns)
    &gt;&gt;&gt; # Compute the Pearson correlation matrix
    &gt;&gt;&gt; correlation_matrix = pearson_analyzer.corr()
    &gt;&gt;&gt; # Generate the heatmap
    &gt;&gt;&gt; pearson_analyzer.heatmap()
</code></pre>
</details>
            <details class="quote">
              <summary>Source code in <code>neural_net\utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Pearson</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the Pearson correlation matrix and generates a heatmap.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input data containing features.</span>
<span class="sd">        n : int</span>
<span class="sd">            number of observations</span>
<span class="sd">        k: int</span>
<span class="sd">            number of features</span>
<span class="sd">        cols: list</span>
<span class="sd">            list of fed columns</span>
<span class="sd">        cov: numpy.ndarray</span>
<span class="sd">            covariance matrix</span>
<span class="sd">        var: numpy.ndarray</span>
<span class="sd">            variance matrix</span>
<span class="sd">        corr: numpy.ndarray</span>
<span class="sd">            correlation matrix</span>

<span class="sd">    Methods:</span>
<span class="sd">        __init__(X:numpy.ndarray,cols:list=None)-&gt;None:</span>
<span class="sd">            Initialize Pearson object</span>
<span class="sd">        corr()-&gt;numpy.ndarray:</span>
<span class="sd">            computes Pearson correlation matrix</span>
<span class="sd">        heatmap(ax=None,fontsize:int=6,digits:int=1, xrotation:Union[int,str]=45,yrotation:Union[int,str]=&#39;horizontal&#39;) -&gt; None:</span>
<span class="sd">            plots correlation heatmap</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">            &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">            &gt;&gt;&gt; from matplotlib import pyplot as plt</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create a sample dataset</span>
<span class="sd">            &gt;&gt;&gt; data = pd.DataFrame({</span>
<span class="sd">            ...     &#39;feature1&#39;: [1, 2, 3, 4, 5],</span>
<span class="sd">            ...     &#39;feature2&#39;: [5, 4, 3, 2, 1],</span>
<span class="sd">            ...     &#39;feature3&#39;: [3, 3, 3, 3, 3]</span>
<span class="sd">            ... })</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Initialize the Pearson correlation analyzer</span>
<span class="sd">            &gt;&gt;&gt; pearson_analyzer = Pearson(X=data.values,cols=data.columns)</span>
<span class="sd">            &gt;&gt;&gt; # Compute the Pearson correlation matrix</span>
<span class="sd">            &gt;&gt;&gt; correlation_matrix = pearson_analyzer.corr()</span>
<span class="sd">            &gt;&gt;&gt; # Generate the heatmap</span>
<span class="sd">            &gt;&gt;&gt; pearson_analyzer.heatmap()</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">cols</span><span class="p">:</span><span class="nb">list</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize Pearson object</span>

<span class="sd">        Args:</span>
<span class="sd">            X:numpy.ndarray</span>
<span class="sd">                array for which you&#39;d like to get correlations from</span>
<span class="sd">            cols: list</span>
<span class="sd">                list of labels for columns</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cols</span> <span class="o">=</span> <span class="n">cols</span> <span class="ow">or</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">corr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov</span> <span class="o">=</span> <span class="p">(</span><span class="n">v</span><span class="o">:=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var</span> <span class="o">=</span> <span class="p">(</span><span class="n">std</span><span class="o">:=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">var</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span>
    <span class="k">def</span> <span class="nf">heatmap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">fontsize</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">digits</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">xrotation</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span><span class="nb">str</span><span class="p">]</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span><span class="n">yrotation</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span><span class="nb">str</span><span class="p">]</span><span class="o">=</span><span class="s1">&#39;horizontal&#39;</span><span class="p">):</span>    
        <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span> <span class="ow">or</span>  <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">)</span>
        <span class="n">im</span><span class="o">.</span><span class="n">set_clim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">(</span><span class="n">ticks</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)),</span> <span class="n">labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cols</span><span class="p">,</span><span class="n">rotation</span><span class="o">=</span><span class="n">xrotation</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">(</span><span class="n">ticks</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)),</span> <span class="n">labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cols</span><span class="p">,</span><span class="n">rotation</span><span class="o">=</span><span class="n">yrotation</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">digits</span><span class="p">)[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">fontsize</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
        <span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">% .2f</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="neural_net.utils.Pearson.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initialize Pearson object</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>X</code></b>
                  (<code><span title="numpy.ndarray">ndarray</span></code>)
              –
              <div class="doc-md-description">
                <p>numpy.ndarray
array for which you'd like to get correlations from</p>
              </div>
            </li>
            <li>
              <b><code>cols</code></b>
                  (<code>list</code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>list
list of labels for columns</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">:</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span><span class="n">cols</span><span class="p">:</span><span class="nb">list</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize Pearson object</span>

<span class="sd">    Args:</span>
<span class="sd">        X:numpy.ndarray</span>
<span class="sd">            array for which you&#39;d like to get correlations from</span>
<span class="sd">        cols: list</span>
<span class="sd">            list of labels for columns</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cols</span> <span class="o">=</span> <span class="n">cols</span> <span class="ow">or</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>



<div class="doc doc-object doc-function">



<h2 id="neural_net.utils.get_module_path" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_module_path</span><span class="p">(</span><span class="nb">dir</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Returns the path to a subdirectory named 'dir' relative to the currently executed script.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>dir</code></b>
                  (<code>str</code>)
              –
              <div class="doc-md-description">
                <p>path to the subdirectory.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>str</code></b>(                <code>str</code>
)            –
            <div class="doc-md-description">
              <p>Absolute path to the specified subdirectory.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_module_path</span><span class="p">(</span><span class="nb">dir</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the path to a subdirectory named &#39;dir&#39; relative to the currently executed script.</span>

<span class="sd">    Args:</span>
<span class="sd">        dir (str): path to the subdirectory.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Absolute path to the specified subdirectory.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)),</span><span class="o">*</span><span class="nb">dir</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="neural_net.utils.make_circle_data" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">make_circle_data</span><span class="p">(</span><span class="n">centers</span><span class="p">,</span> <span class="n">radii</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">n_grid</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Generates random data points distributed within circles.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>centers</code></b>
              –
              <div class="doc-md-description">
                <p>list of tuples
List of (x, y) coordinates representing the centers of circles.</p>
              </div>
            </li>
            <li>
              <b><code>radii</code></b>
              –
              <div class="doc-md-description">
                <p>list of floats
List of radii for each circle.</p>
              </div>
            </li>
            <li>
              <b><code>p</code></b>
              –
              <div class="doc-md-description">
                <p>float, optional (default=0.2)
Percentage of randomly picked data points outside the circles.</p>
              </div>
            </li>
            <li>
              <b><code>n_grid</code></b>
              –
              <div class="doc-md-description">
                <p>int, optional (default=100)
Meshgrid parameter for creating the grid of points.</p>
              </div>
            </li>
            <li>
              <b><code>xmin</code></b>
              –
              <div class="doc-md-description">
                <p>int, optional (default=-100)
Minimum x limit for the data points.</p>
              </div>
            </li>
            <li>
              <b><code>xmax</code></b>
              –
              <div class="doc-md-description">
                <p>int, optional (default=100)
Maximum x limit for the data points.</p>
              </div>
            </li>
            <li>
              <b><code>ymin</code></b>
              –
              <div class="doc-md-description">
                <p>int, optional (default=-100)
Minimum y limit for the data points.</p>
              </div>
            </li>
            <li>
              <b><code>ymax</code></b>
              –
              <div class="doc-md-description">
                <p>int, optional (default=100)
Maximum y limit for the data points.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>X</code></b>(                <code>tuple</code>
)            –
            <div class="doc-md-description">
              <p>numpy.ndarray, shape (n_samples, 2)
2D matrix of features (coordinates of data points).</p>
            </div>
          </li>
          <li>
<b><code>y</code></b>(                <code>tuple</code>
)            –
            <div class="doc-md-description">
              <p>numpy.ndarray, shape (n_samples,1)
Labels corresponding to the data points (1 if inside a circle, 0 otherwise).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
<details class="example" open>
  <summary>Example</summary>
  <pre><code class="language-python">    &gt;&gt;&gt; centers = [(0, 0), (20, 30)]
    &gt;&gt;&gt; radii = [10, 15]
    &gt;&gt;&gt; X, y = make_circle(centers, radii, p=0.1)
    &gt;&gt;&gt; print(X.shape, y.shape)
    (200, 2) (200,1)
</code></pre>
</details>
          <details class="quote">
            <summary>Source code in <code>neural_net\utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">make_circle_data</span><span class="p">(</span><span class="n">centers</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span><span class="n">radii</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span><span class="n">p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span><span class="n">n_grid</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">xmin</span><span class="p">:</span><span class="nb">int</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span><span class="n">xmax</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">ymin</span><span class="p">:</span><span class="nb">int</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span><span class="n">ymax</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span><span class="o">-&gt;</span><span class="nb">tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates random data points distributed within circles.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        centers : list of tuples</span>
<span class="sd">            List of (x, y) coordinates representing the centers of circles.</span>
<span class="sd">        radii : list of floats</span>
<span class="sd">            List of radii for each circle.</span>
<span class="sd">        p : float, optional (default=0.2)</span>
<span class="sd">            Percentage of randomly picked data points outside the circles.</span>
<span class="sd">        n_grid : int, optional (default=100)</span>
<span class="sd">            Meshgrid parameter for creating the grid of points.</span>
<span class="sd">        xmin : int, optional (default=-100)</span>
<span class="sd">            Minimum x limit for the data points.</span>
<span class="sd">        xmax : int, optional (default=100)</span>
<span class="sd">            Maximum x limit for the data points.</span>
<span class="sd">        ymin : int, optional (default=-100)</span>
<span class="sd">            Minimum y limit for the data points.</span>
<span class="sd">        ymax : int, optional (default=100)</span>
<span class="sd">            Maximum y limit for the data points.</span>

<span class="sd">    Returns:</span>
<span class="sd">        X : numpy.ndarray, shape (n_samples, 2)</span>
<span class="sd">            2D matrix of features (coordinates of data points).</span>
<span class="sd">        y : numpy.ndarray, shape (n_samples,1)</span>
<span class="sd">            Labels corresponding to the data points (1 if inside a circle, 0 otherwise).</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">            &gt;&gt;&gt; centers = [(0, 0), (20, 30)]</span>
<span class="sd">            &gt;&gt;&gt; radii = [10, 15]</span>
<span class="sd">            &gt;&gt;&gt; X, y = make_circle(centers, radii, p=0.1)</span>
<span class="sd">            &gt;&gt;&gt; print(X.shape, y.shape)</span>
<span class="sd">            (200, 2) (200,1)</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span><span class="n">xmax</span><span class="p">,</span><span class="n">n_grid</span><span class="p">),</span><span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span><span class="n">ymax</span><span class="p">,</span><span class="n">n_grid</span><span class="p">)</span>
    <span class="n">xm</span><span class="p">,</span><span class="n">ym</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="n">x_news</span><span class="p">,</span><span class="n">y_news</span> <span class="o">=</span> <span class="p">[],[]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_centers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">centers</span><span class="p">)</span>
    <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_centers</span><span class="p">):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="n">xm</span><span class="o">-</span><span class="n">centers</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">ym</span><span class="o">-</span><span class="n">centers</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">&lt;=</span> <span class="n">radii</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">x_new</span><span class="p">,</span><span class="n">y_new</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span>
        <span class="n">n_sample</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">p</span><span class="p">))</span>
        <span class="n">ix</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">n_sample</span><span class="p">)</span>
        <span class="n">x_news</span> <span class="o">+=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="n">x_new</span><span class="p">][</span><span class="n">ix</span><span class="p">]]</span>
        <span class="n">y_news</span> <span class="o">+=</span> <span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">y_new</span><span class="p">][</span><span class="n">ix</span><span class="p">]]</span>
        <span class="n">labels</span> <span class="o">+=</span> <span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">n_sample</span>
        <span class="n">j</span><span class="o">+=</span><span class="mi">1</span>
    <span class="n">x_news</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">x_news</span><span class="p">)</span>
    <span class="n">y_news</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_news</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x_news</span><span class="p">,</span><span class="n">y_news</span><span class="p">],</span><span class="n">labels</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="neural_net.utils.now" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">now</span><span class="p">()</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Returns the current timestamp as an integer.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>int</code></b>(                <code>int</code>
)            –
            <div class="doc-md-description">
              <p>Current timestamp (number of seconds since the epoch).</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary>Source code in <code>neural_net\utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">now</span><span class="p">()</span><span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the current timestamp as an integer.</span>

<span class="sd">    Returns:</span>
<span class="sd">        int: Current timestamp (number of seconds since the epoch).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">timestamp</span><span class="p">())</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="neural_net.utils.unfold" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">unfold</span><span class="p">(</span><span class="n">d</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Unfolds a nested dictionary by appending the values of inner dictionaries to the outer dictionary.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>d</code></b>
                  (<code>dict</code>)
              –
              <div class="doc-md-description">
                <p>Input dictionary with nested dictionaries.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>dict</code></b>(                <code>dict</code>
)            –
            <div class="doc-md-description">
              <p>Unfolded dictionary with concatenated keys.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>      <p>Example:</p>
<pre><code class="language-python">        &gt;&gt;&gt; d = {'a':1,'b':{'c':2,'d':4}}
        &gt;&gt;&gt; unfold(d)
        {'a': 1, 'b_c': 2, 'b_d': 4}
</code></pre>

          <details class="quote">
            <summary>Source code in <code>neural_net\utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">unfold</span><span class="p">(</span><span class="n">d</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Unfolds a nested dictionary by appending the values of inner dictionaries to the outer dictionary.</span>

<span class="sd">    Args:</span>
<span class="sd">        d (dict): Input dictionary with nested dictionaries.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: Unfolded dictionary with concatenated keys.</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">            &gt;&gt;&gt; d = {&#39;a&#39;:1,&#39;b&#39;:{&#39;c&#39;:2,&#39;d&#39;:4}}</span>
<span class="sd">            &gt;&gt;&gt; unfold(d)</span>
<span class="sd">            {&#39;a&#39;: 1, &#39;b_c&#39;: 2, &#39;b_d&#39;: 4}</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_d</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="s1">&#39;keys&#39;</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
                <span class="n">new_d</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_d</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">new_d</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../how-to-guides/" class="btn btn-neutral float-left" title="How-To Guides"><span class="icon icon-circle-arrow-left"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../how-to-guides/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
      <script src="../javascripts/mathjaxhelper.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
